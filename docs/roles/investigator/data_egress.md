# Data egress process

Data Safe Havens are used for doing secure data research on a single 'work package' of data.
Once you have finished working with the data for your project, you'll have to egress any outputs of your work before the environment is shutdown.

## Classification

The first stage of egressing outputs is to classify them.
This follows the {ref}`same workflow <process_data_classification>` as for {ref}`data ingress <role_investigator_egress>`.

```{hint}
Get the same people who ran the ingress classification process to do this - {ref}`Data Provider Representive <role_data_provider_representative>`, {ref}`role_investigator` and {ref}`role_referee` (optional).
```

```{note}
Each time you want to bring code or data out of the environment, you'll have to classify this data as a new work package.
```

## Bringing data out of the environment

Once the classification is agreed, make sure that your {ref}`role_data_provider_representative` discusses the best way to extract your outputs from the environment with your {ref}`role_system_manager`.

```{note}
You might want to define multiple data collections for egress, which would each have their own sensitivity classification. For example, you might separate a low-sensitivity written report from a high-sensitivity derived dataset.
```
