#cloud-config

apt:
  # Preserves the existing /etc/apt/sources.list
  preserve_sources_list: true

  # Update apt database on first boot (ie run apt-get update)
  update: true

  # Add repositories
  sources:
    marutter-c2d4u35.list:
      source: "ppa:marutter/c2d4u3.5"

    rproject-cran35.list:
      source: "deb https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/"
      keyserver: hkp://keyserver.ubuntu.com:80
      keyid: 51716619E084DAB9

# List of packages to install with apt-get
packages:
  - adcli
  - attr
  - krb5-kdc
  - ldap-utils
  - libmariadb-client-lgpl-dev
  - libnss-ldap
  - libnss-sss
  - libpam-ldap
  - libpam-sss
  - libpq-dev
  - octave
  - oddjob
  - oddjob-mkhomedir
  - postgresql
  - postgresql-contrib
  - r-base
  - r-base-core
  - r-base-dev
  - r-bioc-limma
  - r-bioc-phyloseq
  - r-bioc-rbgl
  - r-cran-ada
  - r-cran-bbmisc
  - r-cran-bitops
  - r-cran-car
  - r-cran-caret
  - r-cran-checkmate
  - r-cran-chron
  - r-cran-coda
  - r-cran-colorramps
  - r-cran-coxboost
  - r-cran-cvst
  - r-cran-deepnet
  - r-cran-devtools
  - r-cran-diagrammer
  - r-cran-dichromat
  - r-cran-doparallel
  - r-cran-dt
  - r-cran-dygraphs
  - r-cran-e1071
  - r-cran-factominer
  - r-cran-foreach
  - r-cran-gbm
  - r-cran-gdata
  - r-cran-ggmap
  - r-cran-ggvis
  - r-cran-glmnet
  - r-cran-googlevis
  - r-cran-hmisc
  - r-cran-irace
  - r-cran-iterators
  - r-cran-kernlab
  - r-cran-kknn
  - r-cran-leaflet
  - r-cran-lme4
  - r-cran-maps
  - r-cran-maptools
  - r-cran-matrixstats
  - r-cran-mboost
  - r-cran-mclust
  - r-cran-mcmcpack
  - r-cran-mlr
  - r-cran-multcomp
  - r-cran-neuralnet
  - r-cran-parallelmap
  - r-cran-paramhelpers
  - r-cran-party
  - r-cran-pls
  - r-cran-quantmod
  - r-cran-randomforest
  - r-cran-randomforestsrc
  - r-cran-ranger
  - r-cran-rcpparmadillo
  - r-cran-rcurl
  - r-cran-repr
  - r-cran-reshape
  - r-cran-rgl
  - r-cran-rjava
  - r-cran-rmysql
  - r-cran-rocr
  - r-cran-roxygen2
  - r-cran-rpostgresql
  - r-cran-rsqlite
  - r-cran-rstan
  - r-cran-rweka
  - r-cran-sqldf
  - r-cran-tcltk2
  - r-cran-testthat
  - r-cran-tgp
  - r-cran-threejs
  - r-cran-tidyverse
  - r-cran-uuid
  - r-cran-vcd
  - r-cran-xgboost
  - r-cran-xlsx
  - r-cran-xts
  - r-recommended
  - realmd
  - sssd
  - sssd-tools
  - xfce4
  - xfce4-terminal
  - xrdp

bootcmd:
  # Update NVidia repository before installing any packages
  - curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | apt-key add -

runcmd:
  # Update conda
  - echo "*** Updating conda installation... ***"
  - conda update -n base -c defaults conda
  # NB. Do not add /anaconda/bin to the PATH since conda must be used through a shell function, not directly as the executable
  - . /anaconda/etc/profile.d/conda.sh
  - echo ". /anaconda/etc/profile.d/conda.sh" >> /etc/bash.bashrc
  # Add channels
  - conda config --add channels bioconda
  - conda config --add channels conda-forge
  - conda config --add channels imperial-college-research-computing
  - conda config --add channels pytorch
  - conda config --add channels r
  # Do not privilege some channels over others
  - conda config --set channel_priority false
  # Increase timeouts and retries for downloading packages (we had some connection issues in testing)
  - conda config --set remote_connect_timeout_secs 30
  - conda config --set remote_max_retries 10
  - conda config --set remote_read_timeout_secs 120
  # List initial environments
  - echo "*** Initial conda environments... ***"
  - conda env list

  # ***** START DEFINING PACKAGES FOR ANACONDA ***
  # DO NOT EDIT BY HAND: Update the requested-<python version> lists then run generate_python_package_specs.sh to re-generate this section
  - export PY_COMMON_PACKAGES="alabaster appdirs asn1crypto astroid astropy attrs babel backports backports.shutil_get_terminal_size basemap beautifulsoup4 bitarray bkcharts blas blaze bleach blosc bokeh boto boto3 botocore bottleneck bz2file bzip2 ca-certificates cairo certifi cffi chardet click cloudpickle clyent colorama configparser contextlib2 cryptography curl cycler cython cytoolz dask dask-core datashape dbus decorator distributed docutils dtw entrypoints et_xmlfile expat fastcache fbprophet filelock flask flask-cors fontconfig freetype future gensim geopandas get_terminal_size gevent glib glob2 gmp gmplot gmpy2 graph_tool graphite2 greenlet gst-plugins-base gstreamer h5py harfbuzz hdf5 heapdict html5lib icu idna imageio imagesize intel-openmp ipykernel ipython ipython_genutils ipywidgets isort itsdangerous jbig jdcal jedi jinja2 jmespath jpeg jsonschema jupyter jupyter_client jupyter_console jupyter_core jupyterlab jupyterlab_launcher keras kiwisolver lazy-object-proxy llvmlite locket lxml lzo markupsafe matplotlib mccabe mistune mkl mkl-service mkl_fft mkl_random more-itertools mpc mpfr mpmath msgpack-python multipledispatch navigator-updater nbconvert nbformat ncurses networkx nltk nose notebook numba numexpr numpy numpy-base numpydoc odo olefile openpyxl openssl packaging pandas pandas-datareader pandas-profiling pandasql pandoc pandocfilters pango parso partd patchelf path.py pathlib2 patsy pcre pep8 pexpect pickleshare pillow pip pixman pkginfo plotly pluggy ply prometheus_client prompt_toolkit protobuf psutil ptyprocess py pyLDAvis pycodestyle pycosat pycparser pycrypto pycurl pyflakes pygments pygpu pylint pymc3 pyodbc pyopenssl pyparsing pyqt pysocks pystan pytables pytest python python-dateutil python-geohash python-louvain pytorch pytz pywavelets pyyaml pyzmq qt qtawesome qtconsole qtpy r-irkernel readline requests rope rpy2 ruamel.yaml s3transfer scikit-image scikit-learn scipy seaborn send2trash setuptools simplegeneric singledispatch sip six snappy snowballstemmer sortedcollections sortedcontainers spacy sphinx sphinxcontrib sphinxcontrib-websupport spyder sqlalchemy sqlite statsmodels sympy tblib tensorflow tensorflow-gpu terminado testpath tk toolz torchvision tornado tqdm traitlets tsfresh typing unicodecsv unixodbc urllib3 wcwidth webencodings werkzeug wheel widgetsnbextension wrapt xlrd xlsxwriter xlwt xz yaml zeromq zict zlib zope zope.interface"
  - export PY_27_PACKAGES="_ipyw_jlab_nb_ext_conf atomicwrites automat backports.functools_lru_cache backports_abc cdecimal constantly defusedxml digits enum34 ffmpeg flask-socketio flask-wtf freeglut fribidi funcsigs functools32 futures gevent-websocket grin hyperlink hypothesis incremental ipaddress jasper leveldb libxslt linecache2 lmdb monocle opencv pathlib py-opencv pyasn1 pyasn1-modules pycairo pydot python-engineio python-magic python-nvd3 python-slugify python-socketio ruamel_yaml scandir scikit-fmm service_identity spyder-kernels ssl_match_hostname subprocess32 traceback2 twisted unidecode unittest2 wordcloud_ipyw_jlab_nb_ext_conf wtforms"
  - export PY_35_PACKAGES="_nb_ext_conf absl-py adal alembic astor async_generator backcall cached-property catboost chainer colour cuda90 cupy dlib fasteners fastparquet fastrlock flake8 flaky gast graphviz grpcio h2o hdijupyterutils hyperopt isodate joblib jupyterhub jupyterhub-ldapauthenticator keras-applications keras-preprocessing krb5 lightgbm mako markdown mock monotonic mpi4py msrest msrestazure nb_anacondacloud nb_conda nb_conda_kernels nbpresent nbsphinx ninja nose-parameterized oauthlib onnx pamela pbr psycopg2 pyaudio pydicom pyglet pyjwt pykerberos pymongo pytest-arraydiff pytest-astropy pytest-doctestplus pytest-openfiles pytest-remotedata pytest-runner python-editor python-oauth2 pytools requests-file requests-ftp requests-kerberos requests-oauthlib requests-toolbelt resampy retrying smart_open sparkmagic sphinx_rtd_theme sudospawner tabulate tensorboard termcolor theano thrift twine wget wordcloudalabaster xgboost"
  - export PY_36_PACKAGES="absl-py adal alembic argcomplete astor async_generator atomicwrites audioread automat backcall backports.tempfile backports.weakref bcrypt cached-property catboost chainer colour constantly cudatoolkit cudnn cupy defusedxml dlib docker-pycreds fasteners fastparquet fastrlock flake8 flaky fribidi gast graphviz grpcio h2o hdijupyterutils humanfriendly hyperlink hyperopt incremental isodate jeepney joblib jsonpickle jupyterhub jupyterhub-ldapauthenticator keras-applications keras-preprocessing keyring lasagne lightgbm mako markdown markupSafe mock monotonic mpi4py msrest msrestazure nb_anacondacloud nb_conda nb_conda_kernels nbpresent nbsphinx nccl ndg-httpsclient ninja nose-parameterized oauthlib onnx pamela paramiko pbr portalocker psycopg2 pyasn1 pyasn1-modules pyaudio pydicom pyglet pyjwt pykerberos pymongo pynacl pyopengl pyopengl-accelerate pytest-arraydiff pytest-astropy pytest-doctestplus pytest-openfiles pytest-remotedata pytest-runner python-editor python-oauth2 pytools requests-file requests-ftp requests-kerberos requests-oauthlib requests-toolbelt resampy retrying secretstorage service_identity shap smart_open sparkmagic sphinx_rtd_theme spyder-kernels sudospawner tabulate tensorboard termcolor theano thrift twine twisted typed-ast typing-extensions websocket-client wget wordcloud_ipyw_jlab_nb_ext_conf xgboost"
  # Consolidate package lists for each Python version
  - export PYTHON27PACKAGES="$PY_COMMON_PACKAGES $PY_27_PACKAGES"
  - export PYTHON35PACKAGES="$PY_COMMON_PACKAGES $PY_35_PACKAGES"
  - export PYTHON36PACKAGES="$PY_COMMON_PACKAGES $PY_36_PACKAGES"
  # ***** END DEFINING PACKAGES FOR ANACONDA ***
  
  # Create or install conda environments
  # Python 2.7 - add 'auto' channel for monocle only, then remove it
  - echo "*** Working on py27 environment. Will take approximately 30 minutes... ***"
  - conda config --add channels auto
  - if [ "$(conda env list | grep py27)" = "" ]; then conda create -y --verbose --name py27 python=2.7 $PYTHON27PACKAGES; else conda install -y --verbose --name py27 $PYTHON27PACKAGES; fi
  - if [ "$(conda env list | grep py27)" = "" ]; then echo "Could not build python 2.7 environment"; exit 1; fi
  - conda config --remove channels auto
  - export JUPYTER_LOCATION=$(echo "source /anaconda/bin/activate py27; which jupyter" | bash)
  - export JUPYTER_VERSION=$(echo "source /anaconda/bin/activate py27; jupyter --version" | bash)
  - if [ "$JUPYTER_LOCATION" != "" ]; then echo "py27 environment has jupyter (version $JUPYTER_VERSION) at $JUPYTER_LOCATION"; else echo "jupyter not found in python 2.7 environment!"; exit 1; fi
  # Python 3.5
  - echo "*** Working on py35 environment. Will take approximately 90 minutes... ***"
  - if [ "$(conda env list | grep py35)" = "" ]; then conda create -y --verbose --name py35 python=3.5 $PYTHON35PACKAGES; else conda install -y --verbose --name py35 $PYTHON35PACKAGES; fi
  - if [ "$(conda env list | grep py35)" = "" ]; then echo "Could not build python 3.5 environment"; exit 1; fi
  - export JUPYTER_LOCATION=$(echo "source /anaconda/bin/activate py35; which jupyter" | bash)
  - export JUPYTER_VERSION=$(echo "source /anaconda/bin/activate py35; jupyter --version" | bash)
  - if [ "$JUPYTER_LOCATION" != "" ]; then echo "py35 environment has jupyter (version $JUPYTER_VERSION) at $JUPYTER_LOCATION"; else echo "jupyter not found in python 3.5 environment!"; exit 1; fi
  # Python 3.6
  - echo "*** Working on py36 environment. Will take approximately 40 minutes... ***"
  - if [ "$(conda env list | grep py36)" = "" ]; then conda create -y --verbose --name py36 python=3.6 $PYTHON36PACKAGES; else conda install -y --verbose --name py36 $PYTHON36PACKAGES; fi
  - if [ "$(conda env list | grep py36)" = "" ]; then echo "Could not build python 3.6 environment"; exit 1; fi
  - export JUPYTER_LOCATION=$(echo "source /anaconda/bin/activate py36; which jupyter" | bash)
  - export JUPYTER_VERSION=$(echo "source /anaconda/bin/activate py36; jupyter --version" | bash)
  - if [ "$JUPYTER_LOCATION" != "" ]; then echo "py36 environment has jupyter (version $JUPYTER_VERSION) at $JUPYTER_LOCATION"; else echo "jupyter not found in python 3.6 environment!"; exit 1; fi
  # List environments
  - echo "*** Final conda environments... ***"
  - conda env list

  # ***** START DEFINING PACKAGES FOR R ***
  # DO NOT EDIT BY HAND: Update cran.list and bioconductor.list then run generate_r_package_specs.sh to re-generate this section
  - export CRANPACKAGES="'abind', 'ada', 'akima', 'ape', 'assertthat', 'AUC', 'backports', 'BBmisc', 'bedr', 'BiocManager', 'bitops', 'boot', 'brms', 'car', 'care', 'caret', 'checkmate', 'chron', 'class', 'cluster', 'coda', 'codetools', 'colorRamps', 'colorspace', 'COMBAT', 'compiler', 'corrgram', 'corrplot', 'cowplot', 'CoxBoost', 'crayon', 'CVST', 'cvTools', 'data.table', 'datasets', 'dbarts', 'DBI', 'deepnet', 'devtools', 'DiagrammeR', 'dichromat', 'digest', 'directlabels', 'dirichletprocess', 'dlm', 'doBy', 'doParallel', 'dplyr', 'DPpackage', 'DT', 'dtw', 'dummies', 'dygraphs', 'e1071', 'emulator', 'evaluate', 'factoextra', 'FactoMineR', 'fda', 'fields', 'fmsb', 'foreach', 'forecast', 'foreign', 'Formula', 'gamlss.dist', 'gamlss.mx', 'gamlss.nl', 'gamlss.spatial', 'gamlss', 'gbm', 'gdata', 'GGally', 'ggforce', 'ggmap', 'ggplot2', 'ggridges', 'ggvis', 'glmnet', 'googleVis', 'gplots', 'graphics', 'grDevices', 'grid', 'gridExtra', 'gtable', 'h2o', 'highr', 'Hmisc', 'htmltools', 'httpuv', 'httr', 'igraph', 'irace', 'IRdisplay', 'iterators', 'jsonlite', 'kernlab', 'KernSmooth', 'kknn', 'kml', 'kmlShape', 'knitr', 'labeling', 'lattice', 'lazyeval', 'LDAvis', 'leaflet', 'lme4', 'loo', 'lubridate', 'magrittr', 'maps', 'maptools', 'markdown', 'MASS', 'Matrix', 'matrixStats', 'mboost', 'mclust', 'MCMCpack', 'McSpatial', 'methods', 'mgcv', 'mime', 'mlbench', 'mlr', 'multcomp', 'munsell', 'ndtv', 'network', 'networkD3', 'neuralnet', 'nlme', 'nnet', 'parallel', 'parallelMap', 'ParamHelpers', 'party', 'pbdZMQ', 'pls', 'plyr', 'polycor', 'pomp', 'PReMiuM', 'pscl', 'purrr', 'pvclust', 'quanteda', 'quantmod', 'R6', 'randomForest', 'RColorBrewer', 'RCurl', 'readr', 'readtext', 'readxl', 'repr', 'reshape', 'reshape2', 'revealjs', 'rgdal', 'realxl', 'rgeos', 'rgl', 'rJava', 'rmarkdown', 'RMySQL', 'ROCR', 'roxygen2', 'rpart', 'RPostgreSQL', 'rPython', 'RSQLite', 'rstan', 'runjags', 'RWeka', 'Scale', 'scales', 'Seurat', 'shiny', 'slam', 'sna', 'SnowballC', 'sourcetools', 'sp', 'spacyr', 'spatial', 'splines', 'sqldf', 'stargazer', 'stats', 'stats4', 'stm', 'stringi', 'stringr', 'surveillance', 'survival', 'synthpop', 'tcltk2', 'testthat', 'text2vec', 'tgp', 'threejs', 'tibble', 'tidyr', 'tidyr', 'tidytext', 'tidyverse', 'tmap', 'tools', 'topicmodels', 'traj', 'tsne', 'urca', 'utils', 'uuid', 'varbvs', 'vars', 'vcd', 'vioplot', 'viridis', 'visNetwork', 'wordcloud', 'xgboost', 'XLConnect', 'xlsx', 'XML', 'xtable', 'xts', 'yaml', 'zoo'"
  - export BIOCPACKAGES="'apeglm', 'ballgown', 'Biobase', 'ChemmineR', 'clusterProfiler', 'ComplexHeatmap', 'ConsensusClusterPlus', 'cummeRbund', 'dada2', 'DECIPHER', 'DESeq2', 'destiny', 'DirichletMultinomial', 'DMRcate', 'EBSeq', 'edgeR', 'fastseg', 'FlowSOM', 'flowUtils', 'ggtree', 'GOSemSim', 'GOstats', 'graph', 'graphite', 'GSEABase', 'Gviz', 'interactiveDisplayBase', 'KEGGgraph', 'limma', 'made4', 'maftools', 'metagenomeSeq', 'minet', 'MLInterfaces', 'monocle', 'pathview', 'pcaMethods', 'phyloseq', 'RankProd', 'RBGL', 'RDAVIDWebService', 'Rgraphviz', 'safe', 'SC3', 'scater', 'scde', 'scran', 'SNPRelate', 'SPIA', 'supraHex', 'sva', 'TCGAbiolinks', 'TimeSeriesExperiment', 'topGO', 'treeio'"
  # ***** END DEFINING PACKAGES FOR R ***

  # Ensure that R packages are installed
  # Set number of cores R should use to install packages to the number of cores available on the VM
  # (R builds a lot of packages from source so we can get a decent speedup here)
  - Rscript -e "nCores = parallel::detectCores(); options('Ncpus' = nCores); getOption('Ncpus', 1L)"
  # CRAN
  - echo "*** Installing additional R packages... ***"
  - echo "Previously installed CRAN packages:"
  - Rscript -e "installed.packages()[,'Package']"
  - echo "CRAN packages remaining to be installed:"
  - Rscript -e "list.of.packages <- c($CRANPACKAGES); new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,'Package'])]; print(new.packages); if(length(new.packages)) install.packages(new.packages, repos='https://cran.rstudio.com/')"
  # Bioconductor
  - echo "Previously installed BioConductor packages:"
  - Rscript -e "list.of.packages <- c($BIOCPACKAGES); old.packages <- list.of.packages[(list.of.packages %in% installed.packages()[,'Package'])]; print(old.packages);"
  - echo "BioConductor packages remaining to be installed:"
  - Rscript -e "list.of.packages <- c($BIOCPACKAGES); new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,'Package'])]; print(new.packages); if(length(new.packages)) BiocManager::install(new.packages)"
  # Install R packages from custom repos
  - Rscript -e "install.packages('INLA', repos='https://inla.r-inla-download.org/R/testing', dep=TRUE)"
  - Rscript -e "devtools::install_github('dgrtwo/gganimate')"
  # Install RStudio
  - echo "*** Installing RStudio... ***"
  # Ensure RStudio picks up system R rather than Conda R for all users
  - echo "export RSTUDIO_WHICH_R=/usr/bin/R" >> /etc/bash.bashrc
  - cd /tmp
  - wget https://download1.rstudio.org/rstudio-xenial-1.1.463-amd64.deb
  - gdebi --non-interactive rstudio-xenial-1.1.463-amd64.deb
  - rm -f rstudio-xenial-1.1.463-amd64.deb
  - if [ ! -e "/usr/bin/rstudio" ]; then echo "Could not install RStudio"; exit 1; fi

  # Install latest julia version
  - echo "*** Installing Julia... ***"
  - echo "Removing old installation and preparing directory..."
  - sudo rm /usr/bin/julia
  - mkdir -p /opt/julia
  - cd /opt/julia
  - echo "Downloading package..."
  - curl -O https://julialang-s3.julialang.org/bin/linux/x64/1.0/julia-1.0.1-linux-x86_64.tar.gz
  - echo "Installing and cleaning up..."
  - tar -zxf julia-1.0.1-linux-x86_64.tar.gz
  - rm -rf julia-1.0.1-linux-x86_64.tar.gz
  - sed -i 's|\(.*\)"|\1:/opt/julia/julia-1.0.1/bin"|' /etc/environment
  - export PATH=$PATH:/opt/julia/julia-1.0.1/bin
  - echo "export PATH=$PATH:/opt/julia/julia-1.0.1/bin" >> /etc/bash.bashrc
  - if [ "$(which julia)" = "" ]; then echo "Could not install Julia"; exit 1; fi

  # Install spark
  - echo "*** Installing spark... ***"
  - mkdir -p /opt/spark
  - cd /opt/spark
  - curl -O http://apache.mirror.anlx.net/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz
  - tar -zxf spark-2.4.0-bin-hadoop2.7.tgz
  - rm -rf spark-2.4.0-bin-hadoop2.7.tgz
  - sed -i 's|\(.*\)"|\1:/opt/spark/spark-2.4.0-bin-hadoop2.7/bin"|' /etc/environment
  - export PATH=$PATH:/opt/spark/spark-2.4.0-bin-hadoop2.7/bin
  - echo "export PATH=$PATH:/opt/spark/spark-2.4.0-bin-hadoop2.7/bin" >> /etc/bash.bashrc
  - if [ "$(which spark-shell)" = "" ]; then echo "Could not install spark"; exit 1; fi

  # Add torch to the path
  - export PATH=$PATH:/dsvm/tools/torch/bin
  - echo "export PATH=$PATH:/dsvm/tools/torch/bin" >> /etc/bash.bashrc

  # Check for successful installations
  - echo "*** Checking for successful installation... ***"
  # - programming languages
  - if [ "$(which python)" != "" ]; then echo "python $(which python)"; echo "$(python --version)"; else echo "python not found!"; exit 1; fi
  - if [ "$(which R)" != "" ]; then echo "R $(which R)"; echo "$(R --version)"; else echo "R not found!"; exit 1; fi
  - if [ "$(which psql)" != "" ]; then echo "psql $(which psql)\n $(psql --version)"; else echo "psql not found!"; exit 1; fi
  - if [ "$(which julia)" != "" ]; then echo "julia $(which julia)"; echo "$(julia --version)"; else echo "julia not found!"; exit 1; fi
  - if [ "$(which java)" != "" ]; then echo "java $(which java)"; echo "$(java -version)"; else echo "java not found!"; exit 1; fi
  - if [ "$(which dotnet)" != "" ]; then echo "dotnet $(which dotnet)"; echo "$(dotnet --info)"; else echo "dotnet not found!"; exit 1; fi
  - if [ "$(which gcc)" != "" ]; then echo "gcc $(which gcc)"; echo "$(gcc --version)"; else echo "gcc not found!"; exit 1; fi
  - if [ "$(which g++)" != "" ]; then echo "g++ $(which g++)"; echo "$(g++ --version)"; else echo "g++ not found!"; exit 1; fi
  - if [ "$(which gfortran)" != "" ]; then echo "gfortran $(which gfortran)"; echo "$(gfortran --version)"; else echo "gfortran not found!"; exit 1; fi
  # - development tools
  - if [ "$(which bash)" != "" ]; then echo "bash $(which bash)"; echo "$(bash --version)"; else echo "bash not found!"; exit 1; fi
  - if [ "$(which git)" != "" ]; then echo "git $(which git)"; echo "$(git --version)"; else echo "git not found!"; exit 1; fi
  - if [ "$(which htop)" != "" ]; then echo "htop $(which htop)"; echo "$(htop --version)"; else echo "htop not found!"; exit 1; fi
  - if [ "$(which firefox)" != "" ]; then echo "firefox $(which firefox)"; echo "$(firefox --version)"; else echo "firefox not found!"; exit 1; fi
  - if [ "$(which vim)" != "" ]; then echo "vim $(which vim)"; echo "$(vim --version)"; else echo "vim not found!"; exit 1; fi
  - if [ "$(which emacs)" != "" ]; then echo "emacs $(which emacs)"; echo "$(emacs --version)"; else echo "emacs not found!"; exit 1; fi
  - if [ "$(which nano)" != "" ]; then echo "nano $(which nano)"; echo "$(nano --version)"; else echo "nano not found!"; exit 1; fi
  - if [ "$(which code)" != "" ]; then echo "code $(which code)"; echo "$(code --version)"; else echo "code not found!"; exit 1; fi
  - if [ "$(which atom)" != "" ]; then echo "atom $(which atom)"; echo "$(dpkg -s atom)"; else echo "atom not found!"; exit 1; fi
  - if [ "$(which jupyter)" != "" ]; then echo "jupyter $(which jupyter)"; echo "$(jupyter --version)"; else echo "jupyter not found!"; exit 1; fi
  - if [ "$(which docker)" != "" ]; then echo "docker $(which docker)"; echo "$(docker --version)"; else echo "docker not found!"; exit 1; fi
  - if [ "$(which az)" != "" ]; then echo "az $(which az)"; echo "$(az --version)"; else echo "az not found!"; exit 1; fi
  - if [ "$(which azcopy)" != "" ]; then echo "azcopy $(which azcopy)"; echo "$(azcopy --version)"; else echo "azcopy not found!"; exit 1; fi
  - if [ "$(which scala)" != "" ]; then echo "scala $(which scala)"; else echo "scala not found!"; exit 1; fi
  - if [ "$(which th)" != "" ]; then echo "th $(which th)"; else echo "torch not found!"; exit 1; fi
  - if [ "$(which nvidia-smi)" != "" ]; then echo "nvidia-smi $(which nvidia-smi)"; echo "$(nvidia-smi --help)"; else echo "nvidia-smi not found!"; exit 1; fi
  - if [ "$(which rstudio)" != "" ]; then echo "rstudio $(which rstudio)"; echo "$(dpkg -s rstudio)"; else echo "rstudio not found!"; fi
  # Check for missing packages
  - echo "R packages that could not be installed:"
  - Rscript -e "list.of.packages <- c($RPACKAGES); missing.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,'Package'])]; print(missing.packages)"
  - echo "Bioconductor packages that could not be installed:"
  - Rscript -e "list.of.packages <- c($BIOCPACKAGES); missing.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,'Package'])]; print(missing.packages)"

  # Deprovision
  - waagent -deprovision+user -force
  # Fix internet connectivity that is broken by waagent deprovisioning
  - rm /etc/resolv.conf; ln -s /run/systemd/resolve/stub-resolv.conf /etc/resolv.conf

final_message:
  "The system is setup and deprovisioned, after $UPTIME seconds"