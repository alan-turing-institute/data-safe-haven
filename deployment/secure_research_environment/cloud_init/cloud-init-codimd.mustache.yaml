#cloud-config

# Create files
write_files:
  - path: "/etc/apt/apt.conf.d/00proxy"
    permissions: "0444"
    content: |
      Acquire::http::Proxy "http://{{shm.monitoring.updateServers.linux.ip}}:8000";

  - path: "/etc/audit/rules.d/audit.rules"
    permissions: "0400"
    content: |
      {{audit.rules}}

  - path: "/etc/systemd/system/clamav-clamonacc.service"
    permissions: "0644"
    content: |
      {{clamav-clamonacc.service}}

  - path: "/etc/systemd/system/clamav-clamdscan.service"
    permissions: "0644"
    content: |
      {{clamav-clamdscan.service}}

  - path: "/etc/systemd/system/clamav-clamdscan.timer"
    permissions: "0644"
    content: |
      {{clamav-clamdscan.timer}}

  - path: "/opt/codimd/docker-compose.yml"
    permissions: "0400"
    content: |
      version: '3'
      services:
        codimd:
          depends_on:
            - database
          image: hackmdio/hackmd:{{sre.webapps.codimd.codimd.dockerVersion}}
          environment:
            - CMD_ALLOW_ANONYMOUS=false
            - CMD_ALLOW_FREEURL=true
            - CMD_DB_URL=postgres://codimd:{{codimd.postgresPassword}}@database:5432/codimd
            - CMD_EMAIL=false
            - CMD_IMAGE_UPLOAD_TYPE=filesystem
            - CMD_LDAP_BINDCREDENTIALS={{codimd.ldapSearchUserPassword}}
            - CMD_LDAP_BINDDN={{codimd.ldapSearchUserDn}}
            - CMD_LDAP_PROVIDERNAME={{shm.domain.netbiosName}}
            - CMD_LDAP_SEARCHBASE={{shm.domain.ous.researchUsers.path}}
            - CMD_LDAP_SEARCHFILTER={{{codimd.ldapUserFilter}}}
            - CMD_LDAP_URL=ldap://{{shm.dc.fqdn}}
            - CMD_LDAP_USERIDFIELD=sAMAccountName
            - CMD_USECDN=false
          ports:
            # Map port 80 (external) to port 3000 (internal)
            - 80:3000
          networks:
            dockernet:
          restart: always
          volumes:
            - /data/codimd:/codimd/public/uploads
        database:
          image: postgres:{{sre.webapps.codimd.postgres.dockerVersion}}
          environment:
            - POSTGRES_USER=codimd
            - POSTGRES_PASSWORD={{codimd.postgresPassword}}
            - POSTGRES_DB=codimd
          networks:
            dockernet:
          restart: always
          volumes:
            - /data/postgresql:/var/lib/postgresql/data
      networks:
        dockernet:

  - path: "/opt/configuration/set_dns.sh"
    permissions: "0500"
    content: |
      {{set_dns.mustache.sh}}

# Set locale and timezone
locale: en_GB.UTF-8
timezone: {{sre.time.timezone.linux}}

# Set the NTP server
# By default we use Google's NTP servers which are incompatible with other servers due to leap-second smearing
ntp:
  enabled: true
  pools:
    {{#shm.time.ntp.serverAddresses}}
    - {{.}}
    {{/shm.time.ntp.serverAddresses}}

# Configure apt repositories
apt:
  preserve_sources_list: true

# Install necessary apt packages
packages:
  - apt-transport-https
  - auditd
  - ca-certificates
  - clamav
  - clamav-base
  - clamav-daemon
  - clamav-freshclam
  - clamav-unofficial-sigs
  - curl
  - docker.io
  - docker-compose
  - ldap-utils
  - software-properties-common
package_update: true
package_upgrade: true

# We know that exactly one data disk will be attached to this VM and it will be attached as lun1
disk_setup:
  /dev/disk/azure/scsi1/lun1:
    table_type: gpt
    layout: true
    overwrite: true
fs_setup:
  - device: /dev/disk/azure/scsi1/lun1
    partition: 1
    filesystem: ext4
mounts:
  - [/dev/disk/azure/scsi1/lun1-part1, /data, ext4, "defaults,nofail"]

# Set hostname
fqdn: {{sre.webapps.codimd.fqdn}}
hostname: {{sre.webapps.codimd.fqdn}}

# Add the SRE admin (default) and codimddaemon users
users:
  - default
  - name: codimddaemon
    lock_passwd: true  # Lock the password to disable password login
    sudo: false        # This user will not have sudo privileges

# Run other commands
runcmd:
  # Suppress apt prompts and warning messages
  - DEBIAN_FRONTEND=noninteractive
  - export DEBIAN_FRONTEND

  # Clean up installation
  - echo ">=== Cleaning up apt-get packages... ===<"
  - apt update
  - apt-get -y autoremove
  - apt-get clean
  - apt --fix-broken install

  # Ensure that auditd is running and enabled at startup
  - echo ">=== Enabling auditd services... ===<"
  - systemctl start auditd
  - systemctl enable auditd

  # Check server settings
  - echo ">=== DNS ===<"
  - /opt/configuration/set_dns.sh
  - echo ">=== Hostname ===<"
  - hostnamectl
  - echo ">=== Date/time ===<"
  - timedatectl

  # Configuring attached disks
  - echo ">=== Configuring attached disks... ===<"
  - mkdir -p /data/postgresql
  - mkdir -p /data/codimd
  - chown -R 1500:1500 /data/codimd  # allow the 'codimd' user inside the docker container to access this volume
  - ls -alh /data/

  # Ensure that Docker is running and enabled at startup
  - echo ">=== Configuring Docker... ===<"
  - systemctl enable docker
  - systemctl start docker
  - sleep 1m
  - systemctl status docker
  - docker --version
  - docker-compose --version

  # Set up the codimddaemon user
  - echo ">=== Configuring codimddaemon user... ===<"
  - groupadd docker 2> /dev/null
  - usermod -aG docker codimddaemon
  - newgrp docker
  - chown -R codimddaemon:codimddaemon /opt/codimd
  - ls -alh /opt/codimd

  # Deploy CodiMD using Docker
  - echo ">=== Deploying CodiMD with Docker... ===<"
  - su codimddaemon -c "docker-compose -f /opt/codimd/docker-compose.yml up -d"

  # Wait for deployment to finish
  - |
    while true; do
      CODIMD_STATUS=$(docker-compose -f /opt/codimd/docker-compose.yml logs codimd | grep "HTTP Server listening at 0.0.0.0:3000")
      POSTGRES_STATUS=$(docker-compose -f /opt/codimd/docker-compose.yml logs database | grep "ready to accept connections")
      if [ "$CODIMD_STATUS" != "" ] && [ "$POSTGRES_STATUS" != "" ]; then
        break
      fi
      sleep 5
    done
  - docker-compose -f /opt/codimd/docker-compose.yml logs

  # Print a final message
  - echo ">=== Deploying CodiMD with Docker is complete ===<"
  - docker-compose -f /opt/codimd/docker-compose.yml ps

# Shutdown so that we can tell when the job has finished by polling the VM state
power_state:
  mode: poweroff
  message: "Shutting down as a signal that setup is finished"
  timeout: 30
  condition: true
