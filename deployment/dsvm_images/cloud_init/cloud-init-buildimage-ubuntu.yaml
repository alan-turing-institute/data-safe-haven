#cloud-config


# Update package database on first boot (ie. run apt-get update)
package_update: true


# Upgrade installed packages on first boot (ie. run apt-get upgrade)
package_upgrade: true


apt:
  # Preserves the existing /etc/apt/sources.list
  preserve_sources_list: true

  # Add repositories
  sources:
    atom.list:
      source: "deb [arch=amd64] https://packagecloud.io/AtomEditor/atom/any/ any main"
      keyid: 4C6E74D6C0A35108

    chronitis-jupyter.list:
      source: "ppa:chronitis/jupyter"

    marutter-c2d4u35.list:
      source: "ppa:marutter/c2d4u3.5"

    microsoft-prod.list:
      source: "deb [arch=amd64] https://packages.microsoft.com/ubuntu/18.04/prod bionic main"
      keyid: EB3E94ADBE1229CF

    microsoft-azure-cli.list:
      source: "deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ bionic main"
      keyid: EB3E94ADBE1229CF

    postgresql.list:
      source: "deb http://apt.postgresql.org/pub/repos/apt/ bionic-pgdg main"
      keyid: 7FCC7D46ACCC4CF8

    mono-project.list:
      source: "deb https://download.mono-project.com/repo/ubuntu stable-bionic main"
      keyid: 3FA7E0328081BFF6A14DA29AA6A19B38D3D831EF

    nvidia-cuda.list:
      source: "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64 /"
      keyid: F60F4B3D7FA2AF80

    nvidia-ml.list:
      source: "deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 /"

    rproject-cran35.list:
      source: "deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/"
      keyid: 51716619E084DAB9

    vscode.list:
      source: "deb [arch=amd64] https://packages.microsoft.com/repos/vscode stable main"
      keyid: EB3E94ADBE1229CF


write_files:
  - path: "/installation/debinfo_azuredatastudio.yaml"
    permissions: "0400"
    content: |
      hash: 34e6c2c04cce11a52affb17678e05a1a3e4f526948dee80cdbccd3754ed88e6e
      version: 1.16.1
      debfile: azuredatastudio-linux-|VERSION|.deb
      remote: https://azuredatastudiobuilds.blob.core.windows.net/releases/|VERSION|/|DEBFILE|
  - path: "/installation/debinfo_dbeaver.yaml"
    permissions: "0400"
    content: |
      hash: 84e8c082e9fc23a149f6795bfaeb3da71b547a104a122e4a2cbf2f8dad4c862b
      version: 7.0.3
      debfile: dbeaver-ce_|VERSION|_amd64.deb
      remote: https://dbeaver.io/files/|VERSION|/|DEBFILE|
  - path: "/installation/debinfo_rstudio.yaml"
    permissions: "0400"
    content: |
      hash: 99e0f57b7426aa180db1b08163eba7a1a2e1ab033f2a632f6b852d7b23ca0f98
      version: 1.2.5042
      debfile: rstudio-|VERSION|-amd64.deb
      remote: https://download1.rstudio.org/desktop/bionic/amd64/|DEBFILE|
  - path: "/installation/tarinfo_julia.yaml"
    permissions: "0400"
    content: |
      hash: fd6d8cadaed678174c3caefb92207a3b0e8da9f926af6703fb4d1e4e4f50610a
      version_major: 1.4
      version: |VERSION_MAJOR|.1
      tarfile: julia-|VERSION|-linux-x86_64.tar.gz
      remote: https://julialang-s3.julialang.org/bin/linux/x64/|VERSION_MAJOR|/|TARFILE|
  - path: "/installation/tarinfo_spark.yaml"
    permissions: "0400"
    content: |
      hash: 020be52524e4df366eb974d41a6e18fcb6efcaba9a51632169e917c74267dd81
      version: 2.4.5
      tarfile: spark-|VERSION|-bin-hadoop2.7.tgz
      remote: https://downloads.apache.org/spark/spark-|VERSION|/|TARFILE|
  - path: "/installation/analyse_build.py"
    permissions: "0755"
    content: |
      <analyse_build.py>
  - path: "/installation/create_or_update_conda_python_environment.sh"
    permissions: "0500"
    content: |
      <create_or_update_conda_python_environment.sh>
  - path: "/installation/dbeaver_drivers_config.xml"
    permissions: "0444"
    content: |
      <dbeaver_drivers_config.xml>
  - path: "/installation/deprovision.log"
    permissions: "0600"
    content: |
      # Deprovisioning log
  - path: "/installation/deprovision_vm.sh"
    permissions: "0500"
    content: |
      <deprovision_vm.sh>
  - path: "/installation/download_and_install_deb.sh"
    permissions: "0500"
    content: |
      <download_and_install_deb.sh>
  - path: "/installation/download_and_install_tar.sh"
    permissions: "0500"
    content: |
      <download_and_install_tar.sh>
  - path: "/installation/install_postgres_extensions.sql"
    permissions: "0400"
    content: |
      <install_postgres_extensions.sql>
  - path: "/installation/performance_log.csv"
    permissions: "0644"
    content: |
      # Performance log


# List of packages to install with apt-get
packages:
  - <apt_packages.list>


# List of commands to run using `/bin/sh`
runcmd:
  # Log system performance during the installation and record it each minute
  - nohup dstat --mem --cpu --time --output /installation/performance_log.csv 60 > /dev/null &

  # Suppress apt prompts and warning messages then clean up installation
  - echo "Cleaning up unneeded packages"
  - export DEBIAN_FRONTEND=noninteractive
  - apt-get -y autoremove
  - apt-get clean

  # NVidia setup (following https://www.tensorflow.org/install/gpu)
  - echo ">=== $(date +%s) Installing NVidia requirements for tensorflow ===<"
  - apt-get install -y --no-install-recommends nvidia-driver-430
  - apt-get install -y --no-install-recommends cuda-10-1 libcudnn7=7.6.4.38-1+cuda10.1 libcudnn7-dev=7.6.4.38-1+cuda10.1
  - apt-get install -y --no-install-recommends libnvinfer6=6.0.1-1+cuda10.1 libnvinfer-dev=6.0.1-1+cuda10.1 libnvinfer-plugin6=6.0.1-1+cuda10.1

  # Install additional deb/snap packages
  - echo ">=== $(date +%s) Installing deb/snap packages ===<"

  # Azure Data Studio
  - echo "Installing Azure Data Studio"
  - /installation/download_and_install_deb.sh azuredatastudio
  - if [ "$(which azuredatastudio)" = "" ]; then echo "Could not install Azure Data Studio!"; exit 1; fi

  # DBeaver and drivers
  - echo "Installing DBeaver"
  - /installation/download_and_install_deb.sh dbeaver
  - if [ "$(which dbeaver)" = "" ]; then echo "Could not install DBeaver!"; exit 1; fi
  # Install drivers
  - DBEAVER_DRIVER_DIR="/usr/share/dbeaver/drivers/maven/maven-central"
  - mkdir -p ${DBEAVER_DRIVER_DIR}/com.microsoft.sqlserver/
  - wget -nv https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/7.4.1.jre8/mssql-jdbc-7.4.1.jre8.jar -P ${DBEAVER_DRIVER_DIR}/com.microsoft.sqlserver/
  - wget -nv https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/7.4.1.jre8/mssql-jdbc-7.4.1.jre8.pom -P ${DBEAVER_DRIVER_DIR}/com.microsoft.sqlserver/
  - mkdir -p ${DBEAVER_DRIVER_DIR}/org.postgresql/
  - wget -nv https://repo1.maven.org/maven2/org/postgresql/pgjdbc-core-parent/1.1.5/pgjdbc-core-parent-1.1.5.pom -P ${DBEAVER_DRIVER_DIR}/org.postgresql/
  - wget -nv https://repo1.maven.org/maven2/org/postgresql/pgjdbc-versions/1.1.5/pgjdbc-versions-1.1.5.pom -P ${DBEAVER_DRIVER_DIR}/org.postgresql/
  - wget -nv https://repo1.maven.org/maven2/org/postgresql/postgresql/42.2.5/postgresql-42.2.5.jar -P ${DBEAVER_DRIVER_DIR}/org.postgresql/
  - wget -nv https://repo1.maven.org/maven2/org/postgresql/postgresql/42.2.5/postgresql-42.2.5.pom -P ${DBEAVER_DRIVER_DIR}/org.postgresql/
  # Create driver configuration file
  - mv /installation/dbeaver_drivers_config.xml /usr/share/dbeaver/drivers-config.xml
  - echo "-Ddbeaver.drivers.configuration-file=/usr/share/dbeaver/drivers-config.xml" >> /usr/share/dbeaver/dbeaver.ini
  - ls -alh ${DBEAVER_DRIVER_DIR}/*

  # Microsoft ODBC tools
  - echo "Installing Microsoft ODBC tools"
  - ACCEPT_EULA=Y apt-get install -y msodbcsql17 mssql-tools
  - PATH=$PATH:/opt/mssql-tools/bin
  - if [ "$(which sqlcmd)" = "" ]; then echo "Could not install Microsoft ODBC tools!"; exit 1; fi

  # Install PyCharm
  - echo "Installing PyCharm"
  - snap install pycharm-community --classic
  - PATH=$PATH:/snap/bin
  - if [ "$(which pycharm-community)" = "" ]; then echo "Could not install PyCharm!"; exit 1; fi

  # Install RStudio,
  - echo "Installing RStudio"
  - /installation/download_and_install_deb.sh rstudio || exit 1
  - if [ "$(which rstudio)" = "" ]; then echo "Could not install RStudio!"; exit 1; fi

  # Install spark
  - echo "Installing spark"
  - /installation/download_and_install_tar.sh spark || exit 1
  - SPARK_BASE_DIR=$(ls -d /opt/spark/spark*)
  - PATH=$PATH:${SPARK_BASE_DIR}/bin
  - if [ "$(which pycharm-community)" = "" ]; then echo "Could not install PyCharm!"; exit 1; fi

  # Install latest anaconda version (download is ~640MB)
  - echo ">=== $(date +%s) Installing and configuring conda ===<"
  - ANACONDA_INSTALL_SCRIPT="Miniconda3-latest-Linux-x86_64.sh"
  - ANACONDA_REMOTE_URL="https://repo.anaconda.com/miniconda/${ANACONDA_INSTALL_SCRIPT}"
  - echo "Using installer from $ANACONDA_REMOTE_URL"
  - wget -nv $ANACONDA_REMOTE_URL -P /installation/
  - bash /installation/${ANACONDA_INSTALL_SCRIPT} -b -p /anaconda
  - rm /installation/${ANACONDA_INSTALL_SCRIPT}
  # NB. Do not add /anaconda/bin to the PATH since conda must be used through a shell function, not directly as the executable
  - . /anaconda/etc/profile.d/conda.sh
  - echo ". /anaconda/etc/profile.d/conda.sh" >> /etc/bash.bashrc
  # Update conda and add conda-forge (append puts it last in priority order)
  - conda config --append channels conda-forge
  - conda update -y -n base -c defaults conda
  - conda install -y -n base mamba -c conda-forge
  # Increase timeouts and retries for downloading packages (we had some connection issues in testing)
  - conda config --set remote_connect_timeout_secs 60
  - conda config --set remote_max_retries 20
  - conda config --set remote_read_timeout_secs 180
  # List initial environments
  - echo "Initial conda environments:"
  - conda env list

  # Create or update conda environments - approximately 14 hrs: Python 2.7 (5hrs); Python 3.6 (4hrs); Python 3.7 (3hrs)
  # <Python package list>
  - /installation/create_or_update_conda_python_environment.sh py27 "$PYTHON27_CONDA_PACKAGES" "$PYTHON27_PIP_PACKAGES" || exit 1
  - /installation/create_or_update_conda_python_environment.sh py36 "$PYTHON36_CONDA_PACKAGES" "$PYTHON36_PIP_PACKAGES" || exit 1
  - /installation/create_or_update_conda_python_environment.sh py37 "$PYTHON37_CONDA_PACKAGES" "$PYTHON37_PIP_PACKAGES" || exit 1
  # List environments
  - echo "Final conda environments:"
  - conda env list
  # Set 'other' permissions on the anaconda directory to be equal to that of the owner
  # We then remove write access so that site-packages can be used but not altered
  - echo "Updating /anaconda/ permissions"
  - rm -rf /anaconda/.cph_tmp*
  - chmod -R o=u,o-w /anaconda/
  - ls -alh /anaconda/

  # Install any missing R packages - approximately 1 hr
  - echo ">=== $(date +%s) Configuring R environment ===<"
  # <R package list>
  # CRAN
  - echo "Previously installed CRAN packages:"
  - Rscript -e "list.of.packages <- c($CRAN_PACKAGES); old.packages <- list.of.packages[(list.of.packages %in% installed.packages()[,'Package'])]; print(old.packages);"
  - echo "Installing remaining CRAN packages..."
  - Rscript -e "options('Ncpus' = parallel::detectCores()); list.of.packages <- c($CRAN_PACKAGES); new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,'Package'])]; print(new.packages); if(length(new.packages)) install.packages(new.packages, repos='https://cran.rstudio.com/')"
  # Bioconductor
  - echo "Previously installed BioConductor packages:"
  - Rscript -e "list.of.packages <- c($BIOCONDUCTOR_PACKAGES); old.packages <- list.of.packages[(list.of.packages %in% installed.packages()[,'Package'])]; print(old.packages);"
  - echo "Installing remaining BioConductor packages..."
  - Rscript -e "options('Ncpus' = parallel::detectCores()); list.of.packages <- c($BIOCONDUCTOR_PACKAGES); new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,'Package'])]; print(new.packages); if(length(new.packages)) BiocManager::install(new.packages)"
  # Install R packages from custom repos
  - Rscript -e "install.packages('INLA', repos='https://inla.r-inla-download.org/R/testing', dep=TRUE)"
  - Rscript -e "devtools::install_github('dgrtwo/gganimate')"
  - Rscript -e "devtools::install_github('IRkernel/IRkernel')"
  # Ensure that all users will pick up system R when running RStudio
  - echo "export RSTUDIO_WHICH_R=/usr/bin/R" >> /etc/bash.bashrc
  # Check for missing packages
  - MISSING_CRAN_PACKAGES=$(Rscript -e "list.of.packages <- c($CRAN_PACKAGES); missing.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,'Package'])]; print(missing.packages)")
  - if [ "$MISSING_CRAN_PACKAGES" -ne "character(0)" ]; then echo "Could not install CRAN packages - $MISSING_CRAN_PACKAGES"; exit 1; fi
  - MISSING_BIOCONDUCTOR_PACKAGES=$(Rscript -e "list.of.packages <- c($BIOCONDUCTOR_PACKAGES); missing.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,'Package'])]; print(missing.packages)")
  - if [ "$MISSING_BIOCONDUCTOR_PACKAGES" -ne "character(0)" ]; then echo "Could not install Bioconductor packages - $MISSING_BIOCONDUCTOR_PACKAGES"; exit 1; fi

  # Install Julia and packages - approximately 20 minutes
  - echo ">=== $(date +%s) Installing Julia and packages ===<"
  - /installation/download_and_install_tar.sh julia || exit 1
  - JULIA_BASE_DIR=$(ls -d /opt/julia/julia*)
  - PATH=$PATH:${JULIA_BASE_DIR}/bin
  - if [ "$(which julia)" = "" ]; then echo "Could not install Julia!"; exit 1; fi
  # <Julia package list>
  - export JULIA_DEPOT_PATH="${JULIA_BASE_DIR}/depot/"
  - mkdir -p ${JULIA_DEPOT_PATH}
  - sed -i "/DEPOT_PATH/d" ${JULIA_BASE_DIR}/etc/julia/startup.jl
  - echo "push!(DEPOT_PATH, \"${JULIA_DEPOT_PATH}\")" >> ${JULIA_BASE_DIR}/etc/julia/startup.jl
  - export CONDA_JL_HOME="/anaconda/envs/py37/"
  - export PYTHON="${CONDA_JL_HOME}/bin/python"
  - export TF_USE_GPU=1
  - julia -e "using Pkg; Pkg.add($JULIA_PACKAGES); for package in $JULIA_PACKAGES; Pkg.build(package); end" || exit 1
  # Allow users to read the global Julia depot
  - chmod -R o=u,o-w ${JULIA_BASE_DIR}/depot/
  # Ensure that the default Conda environment is the one we have used to build Tensorflow.
  - echo "export CONDA_JL_HOME=${CONDA_JL_HOME}" >> /etc/bash.bashrc
  # Ensure that the first thing on each user's DEPOT_PATH will be the usual default (~/.julia) followed by the global depot
  - echo "export JULIA_DEPOT_PATH=~/.julia:${JULIA_DEPOT_PATH}" >> /etc/bash.bashrc
  - MISSING_JULIA_PACKAGES=$(julia -e "for package in $JULIA_PACKAGES; try; abspath(joinpath(dirname(Base.find_package(package)))); catch e; println(package); end; end;")
  - if [ "$MISSING_JULIA_PACKAGES" ]; then echo "Could not install Julia packages - $MISSING_JULIA_PACKAGES"; exit 1; fi

  # Configure jupyter kernels
  - echo ">=== $(date +%s) Configuring Julia, Python and R kernels for jupyter ===<"
  # Mark the system kernel as not to be used
  - |
    sed -i "s|\"display_name\":.*Python.*|\"display_name\": \"System Python - do not use\",|" /usr/share/jupyter/kernels/python3/kernel.json
  # Add the Julia kernel
  - mv /root/.local/share/jupyter/kernels/julia-1.4 /usr/share/jupyter/kernels/
  # Add the anaconda kernels
  - jupyter kernelspec install /anaconda/envs/py27/share/jupyter/kernels/py27 || exit 1
  - jupyter kernelspec install /anaconda/envs/py36/share/jupyter/kernels/py36 || exit 1
  - jupyter kernelspec install /anaconda/envs/py37/share/jupyter/kernels/py37 || exit 1
  # Add the R kernel
  - R_VERSION=$(R --version | head -n 1 | cut -d' ' -f3)
  - ln -s /usr/local/lib/R/site-library/IRkernel/kernelspec /usr/local/lib/R/site-library/IRkernel/R${R_VERSION}
  - |
    sed -i "s|\"display_name\":.*\R.*|\"display_name\": \"R ${R_VERSION}\",|" /usr/local/lib/R/site-library/IRkernel/kernelspec/kernel.json
  - jupyter kernelspec install /usr/local/lib/R/site-library/IRkernel/R${R_VERSION} || exit 1
  # Log the output kernels
  - echo "Checking installed Jupyter kernels"
  - jupyter kernelspec list

  # Install PostgreSQL extensions
  - echo ">=== $(date +%s) Installing PostgreSQL extensions ===<"
  - while read -r SQLCOMMAND; do echo "=> $SQLCOMMAND <="; sudo -u postgres psql -c "$SQLCOMMAND" || exit 1; done < /installation/install_postgres_extensions.sql

  # Check for successful installations
  - echo ">=== $(date +%s) Checking environment configuration ===<"
  # Set PATH to the current working version which contains all installed packages
  # Also add ~/.local/bin and ~/bin so that any executables that are installed there (eg. by pip) can be used
  # We do this at the end of the script so that
  #   (a) we know this is the PATH that worked when we checked for each package
  #   (b) we only get one entry in /etc/bash.bashrc rather than several with "last-one-wins"
  - PATH="$PATH:\$HOME/.local/bin:\$HOME/bin"
  - echo "Setting PATH to '${PATH}'"
  - echo "export PATH=${PATH}" >> /etc/bash.bashrc
  # Programming languages
  - echo "\n... Programming languages:\n"
  - if [ "$(which dotnet)" ]; then echo "\n\n*dotnet*\n\n$(which dotnet)\n$(dotnet --version)"; else echo "ERROR dotnet not found!"; exit 1; fi
  - if [ "$(which g++)" ]; then echo "\n\n*g++*\n\n$(which g++)\n$(g++ --version)"; else echo "ERRO g++ not found!"; exit 1; fi
  - if [ "$(which gcc)" ]; then echo "\n\n*gcc*\n\n$(which gcc)\n$(gcc --version)"; else echo "ERROR gcc not found!"; exit 1; fi
  - if [ "$(which gfortran)" ]; then echo "\n\n*gfortran*\n\n$(which gfortran)\n$(gfortran --version)"; else echo "ERROR gfortran not found!"; exit 1; fi
  - if [ "$(which java)" ]; then echo "\n\n*java*\n\n$(which java)\n$(java -version)"; else echo "ERROR java not found!"; exit 1; fi
  - if [ "$(which julia)" ]; then echo "\n\n*julia*\n\n$(which julia)\n$(julia --version)"; else echo "ERROR Julia not found!"; exit 1; fi
  - if [ "$(which R)" ]; then echo "\n\n*R*\n\n$(which R)\n$(R --version)"; else echo "ERROR R not found!"; exit 1; fi
  - if [ "$(which scala)" ]; then echo "\n\n*scala*\n\n$(which scala)\n$(scalac -version)"; else echo "ERROR scala not found!"; exit 1; fi
  - if [ "$(which spark-shell)" ]; then echo "\n\n*R*\n\n$(which spark-shell)\n$(spark-shell --version)"; else echo "ERROR spark-shell not found!"; exit 1; fi
  # Editors
  - echo "\n... Editors/IDEs:\n"
  - if [ "$(which atom)" ]; then echo "\n\n*atom*\n\n$(which atom)\n$(dpkg -s atom | grep '^Version:')"; else echo "ERROR atom not found!"; exit 1; fi
  - if [ "$(which code)" ]; then echo "\n\n*code*\n\n$(which code)\n$(code --version)"; else echo "ERROR code not found!"; exit 1; fi
  - if [ "$(which emacs)" ]; then echo "\n\n*emacs*\n\n$(which emacs)\n$(emacs --version)"; else echo "ERROR emacs not found!"; exit 1; fi
  - if [ "$(which nano)" ]; then echo "\n\n*nano*\n\n$(which nano)\n$(nano --version)"; else echo "ERROR nano not found!"; exit 1; fi
  - if [ "$(which pycharm-community)" ]; then echo "\n\n*pycharm*\n\n$(which pycharm-community)\n$(snap list pycharm-community)"; else echo "ERROR PyCharm not found!"; exit 1; fi
  - if [ "$(which rstudio)" ]; then echo "\n\n*RStudio*\n\n$(which rstudio)\n$(dpkg -s rstudio | grep '^Version:')"; else echo "ERROR RStudio not found!"; fi
  - if [ "$(which vim)" ]; then echo "\n\n*vim*\n\n$(which vim)\n$(vim --version | grep '^VIM')"; else echo "ERROR vim not found!"; exit 1; fi
  # Presentation tools
  - echo "\n... Presentation tools:\n"
  - if [ "$(which latex)" ]; then echo "\n\n*latex*\n\n$(which latex)\n$(latex --version | grep 'TeX Live')"; else echo "ERROR latex not found!"; exit 1; fi
  - if [ "$(which libreoffice)" ]; then echo "\n\n*libreoffice*\n\n$(which libreoffice)\n$(libreoffice --version)"; else echo "ERROR libreoffice not found!"; exit 1; fi
  - if [ "$(which pdflatex)" ]; then echo "\n\n*pdflatex*\n\n$(which pdflatex)\n$(pdflatex --version | grep 'TeX Live')"; else echo "ERROR pdflatex not found!"; exit 1; fi
  - if [ "$(which xelatex)" ]; then echo "\n\n*xelatex*\n\n$(which xelatex)\n$(xelatex --version | grep 'TeX Live')"; else echo "ERROR xelatex not found!"; exit 1; fi
  # Development tools
  - echo "\n... Development tools:\n"
  - if [ "$(which azuredatastudio)" ]; then echo "\n\n*azuredatastudio*\n\n$(which azuredatastudio)"; else echo "ERROR azuredatastudio not found!"; exit 1; fi
  - if [ "$(which bash)" ]; then echo "\n\n*bash*\n\n$(which bash)\n$(bash --version | grep 'version')"; else echo "ERROR bash not found!"; exit 1; fi
  - if [ "$(which dbeaver)" ]; then echo "\n\n*DBeaver*\n\n$(which dbeaver)\n$(dpkg -s dbeaver-ce | grep '^Version:')"; else echo "ERROR DBeaver not found!"; exit 1; fi
  - if [ "$(which docker)" ]; then echo "\n\n*Docker*\n\n$(which docker)\n$(docker --version)"; else echo "ERROR Docker not found!"; exit 1; fi
  - if [ "$(which firefox)" ]; then echo "\n\n*Firefox*\n\n$(which firefox)\n$(firefox --version)"; else echo "ERROR Firefox not found!"; exit 1; fi
  - if [ "$(which git)" ]; then echo "\n\n*git*\n\n$(which git)\n$(git --version)"; else echo "ERROR git not found!"; exit 1; fi
  - if [ "$(which htop)" ]; then echo "\n\n*htop*\n\n$(which htop)\n$(htop --version)"; else echo "ERROR htop not found!"; exit 1; fi
  - if [ "$(which nvidia-smi)" ]; then echo "\n\n*nvidia-smi*\n\n$(which nvidia-smi)\n$(modinfo nvidia | grep '^version:')"; else echo "nvidia-ERROR smi not found!"; exit 1; fi
  - if [ "$(which psql)" ]; then echo "\n\n*psql*\n\n$(which psql)\n$(psql --version)"; else echo "ERROR psql not found!"; exit 1; fi
  - if [ "$(which sqlcmd)" ]; then echo "\n\n*sqlcmd*\n\n$(which sqlcmd)\n$(sqlcmd -? | grep Version)"; else echo "ERROR sqlcmd not found!"; exit 1; fi


final_message:
  "System setup through cloud-init is finished. Configuration took $UPTIME seconds"
