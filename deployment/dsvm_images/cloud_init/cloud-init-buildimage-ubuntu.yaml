#cloud-config

# Update package database on first boot (ie. run apt-get update)
package_update: true

# Upgrade installed packages on first boot (ie. run apt-get upgrade)
package_upgrade: true


apt:
  # Preserves the existing /etc/apt/sources.list
  preserve_sources_list: true

  # Add repositories
  sources:
    atom.list:
      source: "deb [arch=amd64] https://packagecloud.io/AtomEditor/atom/any/ any main"
      keyid: 4C6E74D6C0A35108

    chronitis-jupyter.list:
      source: "ppa:chronitis/jupyter"

    marutter-c2d4u35.list:
      source: "ppa:marutter/c2d4u3.5"

    microsoft-prod.list:
      source: "deb [arch=amd64] https://packages.microsoft.com/ubuntu/18.04/prod bionic main"
      keyid: EB3E94ADBE1229CF

    microsoft-azure-cli.list:
      source: "deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ bionic main"
      keyid: EB3E94ADBE1229CF

    postgresql.list:
      source: "deb http://apt.postgresql.org/pub/repos/apt/ bionic-pgdg main"
      keyid: 7FCC7D46ACCC4CF8

    mono-project.list:
      source: "deb https://download.mono-project.com/repo/ubuntu stable-bionic main"
      keyid: 3FA7E0328081BFF6A14DA29AA6A19B38D3D831EF

    nvidia-cuda.list:
      source: "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64 /"
      keyid: F60F4B3D7FA2AF80

    nvidia-ml.list:
      source: "deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 /"

    rproject-cran35.list:
      source: "deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/"
      keyid: 51716619E084DAB9

    vscode.list:
      source: "deb [arch=amd64] https://packages.microsoft.com/repos/vscode stable main"
      keyid: EB3E94ADBE1229CF


write_files:
  - path: "/installation/debinfo_azuredatastudio.yaml"
    permissions: "0400"
    content: |
      hash: 34e6c2c04cce11a52affb17678e05a1a3e4f526948dee80cdbccd3754ed88e6e
      version: 1.16.1
      debfile: azuredatastudio-linux-|VERSION|.deb
      remote: https://azuredatastudiobuilds.blob.core.windows.net/releases/|VERSION|/|DEBFILE|
  - path: "/installation/debinfo_dbeaver.yaml"
    permissions: "0400"
    content: |
      hash: 84e8c082e9fc23a149f6795bfaeb3da71b547a104a122e4a2cbf2f8dad4c862b
      version: 7.0.3
      debfile: dbeaver-ce_|VERSION|_amd64.deb
      remote: https://dbeaver.io/files/|VERSION|/|DEBFILE|
  - path: "/installation/debinfo_rstudio.yaml"
    permissions: "0400"
    content: |
      hash: 99e0f57b7426aa180db1b08163eba7a1a2e1ab033f2a632f6b852d7b23ca0f98
      version: 1.2.5042
      debfile: rstudio-|VERSION|-amd64.deb
      remote: https://download1.rstudio.org/desktop/bionic/amd64/|DEBFILE|
  - path: "/installation/tarinfo_julia.yaml"
    permissions: "0400"
    content: |
      hash: fd6d8cadaed678174c3caefb92207a3b0e8da9f926af6703fb4d1e4e4f50610a
      version_major: 1.4
      version: |VERSION_MAJOR|.1
      pathdir: julia-|VERSION|
      tarfile: julia-|VERSION|-linux-x86_64.tar.gz
      remote: https://julialang-s3.julialang.org/bin/linux/x64/|VERSION_MAJOR|/|TARFILE|
      executable: julia
  - path: "/installation/tarinfo_spark.yaml"
    permissions: "0400"
    content: |
      hash: 020be52524e4df366eb974d41a6e18fcb6efcaba9a51632169e917c74267dd81
      version: 2.4.5
      pathdir: spark-|VERSION|-bin-hadoop2.7
      tarfile: |PATHDIR|.tgz
      remote: https://downloads.apache.org/spark/spark-|VERSION|/|TARFILE|
      executable: spark-shell
  - path: "/installation/deprovision.log"
    permissions: "0600"
    content: |
      # Deprovisioning log
  - path: "/installation/analyse_build.py"
    permissions: "0755"
    content: |
      <analyse_build.py>
  - path: "/installation/create_or_update_conda_python_environment.sh"
    permissions: "0500"
    content: |
      <create_or_update_conda_python_environment.sh>
  - path: "/installation/dbeaver_drivers_config.xml"
    permissions: "0444"
    content: |
      <dbeaver_drivers_config.xml>
  - path: "/installation/deprovision_vm.sh"
    permissions: "0500"
    content: |
      <deprovision_vm.sh>
  - path: "/installation/download_and_install_deb.sh"
    permissions: "0500"
    content: |
      <download_and_install_deb.sh>
  - path: "/installation/download_and_install_tar.sh"
    permissions: "0500"
    content: |
      <download_and_install_tar.sh>
  - path: "/installation/install_postgres_extensions.sql"
    permissions: "0400"
    content: |
      <install_postgres_extensions.sql>

# List of packages to install with apt-get
packages:
  - <apt_packages.list>

runcmd:
  # Make a temporary directory (cloudinit recomends not using /tmp)
  - mkdir /run/cloudinit

  # Suppress apt prompts and warning messages
  - DEBIAN_FRONTEND=noninteractive
  - export DEBIAN_FRONTEND

  # NVidia setup (following https://www.tensorflow.org/install/gpu)
  - echo ">=== $(date +%s) Installing NVidia requirements for tensorflow ===<"
  - apt-get install -y --no-install-recommends nvidia-driver-430
  - apt-get install -y --no-install-recommends cuda-10-1 libcudnn7=7.6.4.38-1+cuda10.1 libcudnn7-dev=7.6.4.38-1+cuda10.1
  - apt-get install -y --no-install-recommends libnvinfer6=6.0.1-1+cuda10.1 libnvinfer-dev=6.0.1-1+cuda10.1 libnvinfer-plugin6=6.0.1-1+cuda10.1

  # Clean up installation - getting to this point takes approximately 30 mins
  - echo ">=== $(date +%s) Cleaning up unneeded packages ===<"
  - apt-get -y autoremove
  - apt-get clean

  # Install latest anaconda version (download is ~640MB)
  - echo ">=== $(date +%s) Installing and configuring conda ===<"
  - ANACONDA_INSTALL_SCRIPT="Miniconda3-latest-Linux-x86_64.sh"
  - ANACONDA_INSTALLER_URL="https://repo.anaconda.com/miniconda/${ANACONDA_INSTALL_SCRIPT}"
  - echo "Using installer from $ANACONDA_INSTALLER_URL"
  - cd /run/cloudinit
  - wget $ANACONDA_INSTALLER_URL
  - bash $ANACONDA_INSTALL_SCRIPT -b -p /anaconda
  - rm $ANACONDA_INSTALL_SCRIPT
  # NB. Do not add /anaconda/bin to the PATH since conda must be used through a shell function, not directly as the executable
  - . /anaconda/etc/profile.d/conda.sh
  - echo ". /anaconda/etc/profile.d/conda.sh" >> /etc/bash.bashrc
  # Update conda and add conda-forge (append puts it last in priority order)
  - conda update -n base -c defaults conda
  - conda config --append channels conda-forge
  # Increase timeouts and retries for downloading packages (we had some connection issues in testing)
  - conda config --set remote_connect_timeout_secs 60
  - conda config --set remote_max_retries 20
  - conda config --set remote_read_timeout_secs 180
  # List initial environments
  - echo "Initial conda environments:"
  - conda env list

  # Create or update conda environments
  # <Python package list>
  # Python 2.7 (6hrs); Python 3.6 (4hrs); Python 3.7 (3hrs)
  - /installation/create_or_update_conda_python_environment.sh py27 "$PYTHON27_CONDA_PACKAGES" "$PYTHON27_PIP_PACKAGES" || exit 1
  - /installation/create_or_update_conda_python_environment.sh py36 "$PYTHON36_CONDA_PACKAGES" "$PYTHON36_PIP_PACKAGES" || exit 1
  - /installation/create_or_update_conda_python_environment.sh py37 "$PYTHON37_CONDA_PACKAGES" "$PYTHON37_PIP_PACKAGES" || exit 1
  # List environments
  - echo "Final conda environments:"
  - conda env list
  # Set 'other' permissions on the anaconda directory to be equal to that of the owner
  # We then remove write access so that site-packages can be used but not altered
  - echo "Updating /anaconda/ permissions"
  - rm -rf /anaconda/.cph_tmp*
  - chmod -R o=u,o-w /anaconda/
  - ls -alh /anaconda/

  # Install R, RStudio and packages - approximately 20 minutes
  - echo ">=== $(date +%s) Installing additional R packages ===<"
  # <R package list>
  # CRAN
  - echo "Previously installed CRAN packages:"
  - Rscript -e "list.of.packages <- c($CRAN_PACKAGES); old.packages <- list.of.packages[(list.of.packages %in% installed.packages()[,'Package'])]; print(old.packages);"
  - echo "Installing remaining CRAN packages..."
  - Rscript -e "options('Ncpus' = parallel::detectCores()); list.of.packages <- c($CRAN_PACKAGES); new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,'Package'])]; print(new.packages); if(length(new.packages)) install.packages(new.packages, repos='https://cran.rstudio.com/')"
  # Bioconductor
  - echo "Previously installed BioConductor packages:"
  - Rscript -e "list.of.packages <- c($BIOCONDUCTOR_PACKAGES); old.packages <- list.of.packages[(list.of.packages %in% installed.packages()[,'Package'])]; print(old.packages);"
  - echo "Installing remaining BioConductor packages..."
  - Rscript -e "options('Ncpus' = parallel::detectCores()); list.of.packages <- c($BIOCONDUCTOR_PACKAGES); new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,'Package'])]; print(new.packages); if(length(new.packages)) BiocManager::install(new.packages)"
  # Install R packages from custom repos
  - Rscript -e "install.packages('INLA', repos='https://inla.r-inla-download.org/R/testing', dep=TRUE)"
  - Rscript -e "devtools::install_github('dgrtwo/gganimate')"
  - Rscript -e "devtools::install_github('IRkernel/IRkernel')"
  # Install RStudio, ensuring that all users will pick up system R when running
  - echo ">=== $(date +%s) Installing RStudio ===<"
  - echo "export RSTUDIO_WHICH_R=/usr/bin/R" >> /etc/bash.bashrc
  - /installation/download_and_install_deb.sh rstudio || exit 1

  # Install Julia and packages
  - echo ">=== $(date +%s) Installing Julia and packages ===<"
  - /installation/download_and_install_tar.sh julia || exit 1
  # - packages are installed on a per-user basis into '~/.julia/' (this is hardcoded)
  # - we therefore install and build the packages before moving them into a common area
  # <Julia package list>
  - export CONDA_JL_HOME="/anaconda/envs/py37/"
  - JULIA_DEPOT_PATH="/opt/julia/${JULIA_VERSION}/depot/"
  - mkdir -p ${JULIA_DEPOT_PATH}
  - echo "push!(DEPOT_PATH, \"${JULIA_DEPOT_PATH}\")" >> /opt/julia/${JULIA_VERSION}/etc/julia/startup.jl
  - julia -e "using Pkg; Pkg.add($JULIA_PACKAGES); for package in $JULIA_PACKAGES; Pkg.build(package); end"
  - mv ~/.julia/* $JULIA_DEPOT_PATH
  - echo "export JULIA_DEPOT_PATH=${JULIA_DEPOT_PATH}" >> /etc/bash.bashrc

  # Configure jupyter kernels
  - echo ">=== $(date +%s) Configuring Julia, Python and R kernels for jupyter ===<"
  # Mark the system kernel as not to be used
  - |
    sed -i "s|\"display_name\":.*Python.*|\"display_name\": \"System Python - do not use\",|" /usr/share/jupyter/kernels/python3/kernel.json
  # Add the Julia kernel
  - mv ~/.local/share/jupyter/kernels/julia-1.4 /usr/share/jupyter/kernels/
  # Add the anaconda kernels
  - jupyter kernelspec install /anaconda/envs/py27/share/jupyter/kernels/py27
  - jupyter kernelspec install /anaconda/envs/py36/share/jupyter/kernels/py36
  - jupyter kernelspec install /anaconda/envs/py37/share/jupyter/kernels/py37
  # Add the R kernel
  - R_VERSION=$(R --version | head -n1 | cut -d' ' -f3)
  - ln -s /usr/local/lib/R/site-library/IRkernel/kernelspec /usr/local/lib/R/site-library/IRkernel/R${R_VERSION}
  - |
    sed -i "s|\"display_name\":.*\R.*|\"display_name\": \"R ${R_VERSION}\",|" /usr/local/lib/R/site-library/IRkernel/kernelspec/kernel.json
  - jupyter kernelspec install /usr/local/lib/R/site-library/IRkernel/R${R_VERSION}
  # Log the output kernels
  - echo "Available Jupyter kernels are:"
  - jupyter kernelspec list

  # Install Azure Data Studio
  - echo ">=== $(date +%s) Installing Azure Data Studio ===<"
  - /installation/download_and_install_deb.sh azuredatastudio || exit 1

  # Install DBeaver and drivers
  - echo ">=== $(date +%s) Installing DBeaver ===<"
  - /installation/download_and_install_deb.sh dbeaver || exit 1
  # Install DBeaver drivers
  - mkdir -p /usr/share/dbeaver/drivers/maven/maven-central/com.microsoft.sqlserver/
  - cd /usr/share/dbeaver/drivers/maven/maven-central/com.microsoft.sqlserver/
  - wget https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/7.4.1.jre8/mssql-jdbc-7.4.1.jre8.jar
  - wget https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/7.4.1.jre8/mssql-jdbc-7.4.1.jre8.pom
  - cd - 2> /dev/null
  - mkdir -p /usr/share/dbeaver/drivers/maven/maven-central/org.postgresql/
  - cd /usr/share/dbeaver/drivers/maven/maven-central/org.postgresql/
  - wget https://repo1.maven.org/maven2/org/postgresql/pgjdbc-core-parent/1.1.5/pgjdbc-core-parent-1.1.5.pom
  - wget https://repo1.maven.org/maven2/org/postgresql/pgjdbc-versions/1.1.5/pgjdbc-versions-1.1.5.pom
  - wget https://repo1.maven.org/maven2/org/postgresql/postgresql/42.2.5/postgresql-42.2.5.jar
  - wget https://repo1.maven.org/maven2/org/postgresql/postgresql/42.2.5/postgresql-42.2.5.pom
  - cd - 2> /dev/null
  # Add driver configuration file
  - mv /installation/dbeaver_drivers_config.xml /usr/share/dbeaver/drivers-config.xml
  - echo "-Ddbeaver.drivers.configuration-file=/usr/share/dbeaver/drivers-config.xml" >> /usr/share/dbeaver/dbeaver.ini
  - ls -alh /usr/share/dbeaver/drivers/maven/maven-central/*

  # Install Microsoft ODBC drivers
  - echo ">=== $(date +%s) Install Microsoft ODBC tools ===<"
  - ACCEPT_EULA=Y apt-get install -y msodbcsql17 mssql-tools
  - PATH=$PATH:/opt/mssql-tools/bin
  - if [ "$(which sqlcmd)" = "" ]; then echo "Could not install Microsoft ODBC tools"; exit 1; fi

  # Install PostgreSQL extensions
  - echo ">=== $(date +%s) Installing PostgreSQL extensions ===<"
  - while read -r SQLCOMMAND; do echo "=> $SQLCOMMAND <="; sudo -u postgres psql -c "$SQLCOMMAND"; done < /installation/install_postgres_extensions.sql

  # Install PyCharm
  - echo ">=== $(date +%s) Installing PyCharm ===<"
  - snap install pycharm-community --classic
  - PATH=$PATH:/snap/bin

  # Install spark
  - echo ">=== $(date +%s) Installing spark ===<"
  - /installation/download_and_install_tar.sh spark || exit 1

  # Check for successful installations
  - echo ">=== $(date +%s) Checking for successful installation ===<"
  # Programming languages
  - echo -e "\n... Programming languages:\n"
  - if [ "$(which dotnet)" != "" ]; then echo "dotnet $(which dotnet)"; echo "$(dotnet --info)"; else echo "dotnet not found!"; exit 1; fi
  - if [ "$(which g++)" != "" ]; then echo "g++ $(which g++)"; echo "$(g++ --version)"; else echo "g++ not found!"; exit 1; fi
  - if [ "$(which gcc)" != "" ]; then echo "gcc $(which gcc)"; echo "$(gcc --version)"; else echo "gcc not found!"; exit 1; fi
  - if [ "$(which gfortran)" != "" ]; then echo "gfortran $(which gfortran)"; echo "$(gfortran --version)"; else echo "gfortran not found!"; exit 1; fi
  - if [ "$(which java)" != "" ]; then echo "java $(which java)"; echo "$(java -version)"; else echo "java not found!"; exit 1; fi
  - if [ "$(which julia)" != "" ]; then echo "julia $(which julia)"; echo "$(julia --version)"; else echo "julia not found!"; exit 1; fi
  - if [ "$(which R)" != "" ]; then echo "R $(which R)"; echo "$(R --version)"; else echo "R not found!"; exit 1; fi
  - if [ "$(which scala)" != "" ]; then echo "scala $(which scala)"; else echo "scala not found!"; exit 1; fi
  # Editors
  - echo -e "\n... Editors:\n"
  - if [ "$(which atom)" != "" ]; then echo "atom $(which atom)"; echo "$(dpkg -s atom)"; else echo "atom not found!"; exit 1; fi
  - if [ "$(which code)" != "" ]; then echo "code $(which code)"; echo "$(code --version)"; else echo "code not found!"; exit 1; fi
  - if [ "$(which emacs)" != "" ]; then echo "emacs $(which emacs)"; echo "$(emacs --version)"; else echo "emacs not found!"; exit 1; fi
  - if [ "$(which nano)" != "" ]; then echo "nano $(which nano)"; echo "$(nano --version)"; else echo "nano not found!"; exit 1; fi
  - if [ "$(which pycharm-community)" != "" ]; then echo "pycharm $(which pycharm-community)"; echo "$(snap list pycharm-community)"; else echo "pycharm not found!"; fi
  - if [ "$(which rstudio)" != "" ]; then echo "rstudio $(which rstudio)"; echo "$(dpkg -s rstudio)"; else echo "rstudio not found!"; fi
  - if [ "$(which vim)" != "" ]; then echo "vim $(which vim)"; echo "$(vim --version)"; else echo "vim not found!"; exit 1; fi
  # Presentation tools
  - echo -e "\n... Presentation tools:\n"
  - if [ "$(which latex)" != "" ]; then echo "latex $(which latex)"; echo "$(latex --version)"; else echo "latex not found!"; exit 1; fi
  - if [ "$(which pdflatex)" != "" ]; then echo "pdflatex $(which pdflatex)"; echo "$(pdflatex --version)"; else echo "pdflatex not found!"; exit 1; fi
  - if [ "$(which xelatex)" != "" ]; then echo "xelatex $(which xelatex)"; echo "$(xelatex --version)"; else echo "xelatex not found!"; exit 1; fi
  - if [ "$(which libreoffice)" != "" ]; then echo "libreoffice $(which libreoffice)"; echo "$(libreoffice --version)"; else echo "libreoffice not found!"; exit 1; fi
  # Development tools
  - echo -e "\n... Development tools:\n"
  - if [ "$(which azuredatastudio)" != "" ]; then echo "azuredatastudio $(which azuredatastudio)"; else echo "azuredatastudio not found!"; exit 1; fi
  - if [ "$(which bash)" != "" ]; then echo "bash $(which bash)"; echo "$(bash --version)"; else echo "bash not found!"; exit 1; fi
  - if [ "$(which dbeaver)" != "" ]; then echo "dbeaver $(which dbeaver)"; else echo "dbeaver not found!"; exit 1; fi
  - if [ "$(which docker)" != "" ]; then echo "docker $(which docker)"; echo "$(docker --version)"; else echo "docker not found!"; exit 1; fi
  - if [ "$(which firefox)" != "" ]; then echo "firefox $(which firefox)"; echo "$(firefox --version)"; else echo "firefox not found!"; exit 1; fi
  - if [ "$(which git)" != "" ]; then echo "git $(which git)"; echo "$(git --version)"; else echo "git not found!"; exit 1; fi
  - if [ "$(which htop)" != "" ]; then echo "htop $(which htop)"; echo "$(htop --version)"; else echo "htop not found!"; exit 1; fi
  - if [ "$(which nvidia-smi)" != "" ]; then echo "nvidia-smi $(which nvidia-smi)"; echo "$(nvidia-smi --help)"; else echo "nvidia-smi not found!"; exit 1; fi
  - if [ "$(which psql)" != "" ]; then echo "psql $(which psql)"; echo"$(psql --version)"; else echo "psql not found!"; exit 1; fi
  # Check for missing packages
  - echo "CRAN packages that could not be installed:"
  - Rscript -e "list.of.packages <- c($CRAN_PACKAGES); missing.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,'Package'])]; print(missing.packages)"
  - echo "Bioconductor packages that could not be installed:"
  - Rscript -e "list.of.packages <- c($BIOCONDUCTOR_PACKAGES); missing.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,'Package'])]; print(missing.packages)"

  # Set PATH to the current working version which contains all installed packages
  # Also add ~/.local/bin and ~/bin so that any executables that are installed there (eg. by pip) can be used
  # We do this at the end of the script so that
  #   (a) we know this is the PATH that worked when we checked for all the above packages
  #   (b) we only get one entry in /etc/bash.bashrc rather than several with "last-one-wins"
  - echo ">=== $(date +%s) Setting PATH ===<"
  - PATH="$PATH:\$HOME/.local/bin:\$HOME/bin"
  - echo "Setting PATH to '${PATH}'"
  - echo "export PATH=${PATH}" >> /etc/bash.bashrc
  - echo ">=== $(date +%s) Finished run commands ===<"

final_message:
  "System setup through cloud-init is finished. Configuration took $UPTIME seconds"
