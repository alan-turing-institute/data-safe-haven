#cloud-config

# Set locale and timezone
locale: en_GB.UTF-8
timezone: Etc/UTC

# Update package database on first boot
package_update: true

# Upgrade installed packages on first boot
package_upgrade: true

apt:
  # Append to the existing /etc/apt/sources.list
  preserve_sources_list: true

  # Add repositories
  sources:
    atom.list:
      source: "deb https://packagecloud.io/AtomEditor/atom/any/ any main"
      keyid: 0A0FAB860D48560332EFB581B75442BBDE9E3B09  # https://packagecloud.io/AtomEditor/atom (https://packagecloud.io/docs#gpg_signing) <support@packagecloud.io>

    # Official DBeaver PPA (from https://dbeaver.io/download/)
    dbeaver.list:
      source: "deb http://ppa.launchpad.net/serge-rider/dbeaver-ce/ubuntu focal main"
      keyid: 30ECE32520D438C21E16BF884A71B51882788FD2  # Launchpad PPA for Serge Rider

    microsoft-general.list:
      source: "deb https://packages.microsoft.com/ubuntu/20.04/prod focal main"
      keyid: BC528686B50D79E339D3721CEB3E94ADBE1229CF  # Microsoft (Release signing) <gpgsecurity@microsoft.com>

    mono-project.list:
      source: "deb https://download.mono-project.com/repo/ubuntu stable-focal main"
      keyid: 3FA7E0328081BFF6A14DA29AA6A19B38D3D831EF  # Xamarin Public Jenkins (auto-signing) <releng@xamarin.com>

    nvidia-cuda.list:
      source: "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64 /"
      keyid: AE09FE4BBD223A84B2CCFCE3F60F4B3D7FA2AF80  # cudatools <cudatools@nvidia.com>

    nvidia-ml-1804.list:
      source: "deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 /"
      keyid: AE09FE4BBD223A84B2CCFCE3F60F4B3D7FA2AF80  # cudatools <cudatools@nvidia.com>

    nvidia-ml-2004.list:
      source: "deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64 /"
      keyid: AE09FE4BBD223A84B2CCFCE3F60F4B3D7FA2AF80  # cudatools <cudatools@nvidia.com>

    postgresql.list:
      source: "deb http://apt.postgresql.org/pub/repos/apt/ focal-pgdg main"
      keyid: B97B0AFCAA1A47F044F244A07FCC7D46ACCC4CF8  # PostgreSQL Debian Repository

    qgis.list:
      source: "deb https://qgis.org/ubuntu focal main"
      keyid: 39877635093F2656019711FAF7E06F06199EF2F2  # QGIS Archive Automatic Signing Key (2020) <qgis-developer@lists.osgeo.org>

    rproject-updates.list:
      source: "deb https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/"
      keyid: E298A3A825C0D65DFD57CBB651716619E084DAB9  # Michael Rutter <marutter@gmail.com>

    sbt.list:
      source: "deb https://dl.bintray.com/sbt/debian /"
      keyid: 2EE0EA64E40A89B84B2DF73499E82A75642AC823  # sbt build tool <scalasbt@gmail.com>

    vscode.list:
      source: "deb https://packages.microsoft.com/repos/vscode stable main"
      keyid: BC528686B50D79E339D3721CEB3E94ADBE1229CF  # Microsoft (Release signing) <gpgsecurity@microsoft.com>


write_files:
  - path: "/etc/jaas.conf"
    owner: root:root
    permissions: "0444"
    content: |
      pgjdbc {
      com.sun.security.auth.module.Krb5LoginModule required
          useTicketCache=true
          debug=true
          renewTGT=true
          doNotPrompt=true;
      };
  - path: "/opt/build/azuredatastudio.debinfo"
    permissions: "0400"
    content: |
      {{deb-azuredatastudio.version}}
  - path: "/opt/build/check_installation.py"
    permissions: "0400"
    content: |
      {{check_installation.py}}
  - path: "/opt/build/dbeaver_drivers_config.xml"
    permissions: "0444"
    content: |
      {{dbeaver_drivers_config.xml}}
  - path: "/opt/build/deprovision_vm.sh"
    permissions: "0500"
    content: |
      {{deprovision_vm.sh}}
  - path: "/opt/build/download_and_install_deb.sh"
    permissions: "0500"
    content: |
      {{download_and_install_deb.sh}}
  - path: "/opt/build/dstat.patch"
    permissions: "0755"
    content: |
      {{dstat.patch}}
  - path: "/opt/build/install_python_version.sh"
    permissions: "0500"
    content: |
      {{install_python_version.sh}}
  - path: "/opt/build/packages/packages-julia.list"
    permissions: "0444"
    content: |
      {{packages-julia.list}}
  - path: "/opt/build/packages/packages-r-bioconductor.list"
    permissions: "0444"
    content: |
      {{packages-r-bioconductor.list}}
  - path: "/opt/build/packages/packages-r-cran.list"
    permissions: "0444"
    content: |
      {{packages-r-cran.list}}
  - path: "/opt/build/python-requirements-py36.txt"
    permissions: "0444"
    content: |
      {{python-requirements-py36.txt}}
  - path: "/opt/build/python-requirements-py37.txt"
    permissions: "0444"
    content: |
      {{python-requirements-py37.txt}}
  - path: "/opt/build/python-requirements-py38.txt"
    permissions: "0444"
    content: |
      {{python-requirements-py38.txt}}
  - path: "/opt/build/python-pyproject-template.toml"
    permissions: "0400"
    content: |
      {{python_pyproject_template.toml}}
  - path: "/opt/build/python-system-packages.txt"
    permissions: "0444"
    content: |
      jill       # for installing Julia
      matplotlib # for PyPlot Julia package
      shui       # for installing Spark/Hadoop
  - path: "/opt/build/rstudio.debinfo"
    permissions: "0400"
    content: |
      {{deb-rstudio.version}}
  - path: "/opt/monitoring/analyse_build.py"
    permissions: "0755"
    content: |
      {{analyse_build.py}}
  - path: "/opt/monitoring/deprovision.log"
    permissions: "0600"
    content: |
      # Deprovisioning log
  - path: "/opt/monitoring/performance_log.csv"
    permissions: "0644"
    content: |
      # Performance log
  - path: "/usr/share/applications/jupyter-notebook.desktop"
    permissions: "0644"
    content: |
      [Desktop Entry]
      Version=1.0
      Type=Application
      Name=Jupyter Notebook
      Exec=jupyter notebook
      Icon=/usr/lib/python3/dist-packages/notebook/static/base/images/favicon.ico
      Categories=Utility;TextEditor;Development;IDE;
  - path: "/usr/share/applications/pycharm.desktop"
    permissions: "0644"
    content: |
      [Desktop Entry]
      Version=1.0
      Type=Application
      Name=PyCharm
      Exec=/snap/bin/pycharm-community
      Icon=/snap/pycharm-community/current/meta/gui/icon.png
      Categories=Utility;TextEditor;Development;IDE;

# List of packages to install with apt-get
packages:
  - {{packages-apt.list}}


# Set the NTP server
# By default we use Google's NTP servers which are incompatible with other servers due to leap-second smearing
ntp:
  enabled: true
  ntp_client: systemd-timesyncd
  pools:
    {{#shm.time.ntp.serverAddresses}}
    - {{.}}
    {{/shm.time.ntp.serverAddresses}}


# List of commands to run using `/bin/sh`
# When changing these lines try to ensure that everything is checked as close as possible to the point when it is installed/configured.
# If any of the installation/configuration checks fail then end the cloud-init process immediately by calling `exit 1`.
# This allows us to (i) not waste time completing a build once a step has failed and (ii) easily tell when and why a build failed using the analyse_build.py script.
runcmd:
  # Log system performance during the installation and record it each minute
  - patch /usr/bin/dstat /opt/build/dstat.patch
  - nohup dstat --mem --cpu --time --output /opt/monitoring/performance_log.csv 60 > /dev/null &
  # Suppress apt prompts and warning messages
  - echo "Suppressing apt prompts"
  - export DEBIAN_FRONTEND=noninteractive
  - sleep 1  # ensure that run commands are cleanly time-separated from other cloud-init commands

  - echo ">=== $(date +%s) Installing additional deb/snap/source packages ===<"
  # Install python packages used in the rest of the build
  - pip3 install -r /opt/build/python-system-packages.txt
  # NVidia setup (necessary packages from https://www.tensorflow.org/install/gpu are in our apt install list)
  - echo "Checking NVidia requirements for tensorflow..."
  - if [ "$(which nvidia-smi)" = "" ]; then echo "Could not install NVidia tools!"; exit 1; else echo "... successfully installed NVidia requirements"; fi
  # Microsoft ODBC tools
  - echo "Installing Microsoft ODBC tools..."
  - ACCEPT_EULA=Y apt-get install -y msodbcsql17 mssql-tools
  - PATH=$PATH:/opt/mssql-tools/bin
  - if [ "$(which sqlcmd)" = "" ]; then echo "Could not install Microsoft ODBC tools!"; exit 1; else echo "... successfully installed Microsoft ODBC tools"; fi
  # Azure Data Studio
  - echo "Installing Azure Data Studio..."
  - /opt/build/download_and_install_deb.sh azuredatastudio
  - if [ "$(which azuredatastudio)" = "" ]; then echo "Could not install Azure Data Studio!"; exit 1; else echo "... successfully installed Azure Data Studio"; fi
  # DBeaver and drivers
  - echo "Installing DBeaver..."
  - if [ "$(which dbeaver)" = "" ]; then echo "Could not install DBeaver!"; exit 1; else echo "... successfully installed DBeaver"; fi
  # Install drivers from maven
  - echo "Installing DBeaver drivers..."
  - DBEAVER_DRIVER_DIR="/usr/share/dbeaver/drivers/maven/maven-central"
  # Note that the filenames specified here have to be kept synchronised with the names in the dbeaver_drivers_config.xml file.
  # Adding new drivers therefore involves changing both this file and the XML file.
  - mkdir -p ${DBEAVER_DRIVER_DIR}/com.microsoft.sqlserver/
  - wget -nv https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/{{dbeaver.drivers.mssql_jdbc}}/mssql-jdbc-{{dbeaver.drivers.mssql_jdbc}}.jar -P ${DBEAVER_DRIVER_DIR}/com.microsoft.sqlserver/
  - wget -nv https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/{{dbeaver.drivers.mssql_jdbc}}/mssql-jdbc-{{dbeaver.drivers.mssql_jdbc}}.pom -P ${DBEAVER_DRIVER_DIR}/com.microsoft.sqlserver/
  - mkdir -p ${DBEAVER_DRIVER_DIR}/org.postgresql/
  - wget -nv https://repo1.maven.org/maven2/org/postgresql/pgjdbc-core-parent/{{dbeaver.drivers.pgjdbc}}/pgjdbc-core-parent-{{dbeaver.drivers.pgjdbc}}.pom -P ${DBEAVER_DRIVER_DIR}/org.postgresql/
  - wget -nv https://repo1.maven.org/maven2/org/postgresql/pgjdbc-versions/{{dbeaver.drivers.pgjdbc}}/pgjdbc-versions-{{dbeaver.drivers.pgjdbc}}.pom -P ${DBEAVER_DRIVER_DIR}/org.postgresql/
  - wget -nv https://repo1.maven.org/maven2/org/postgresql/postgresql/{{dbeaver.drivers.postgresl}}/postgresql-{{dbeaver.drivers.postgresl}}.jar -P ${DBEAVER_DRIVER_DIR}/org.postgresql/
  - wget -nv https://repo1.maven.org/maven2/org/postgresql/postgresql/{{dbeaver.drivers.postgresl}}/postgresql-{{dbeaver.drivers.postgresl}}.pom -P ${DBEAVER_DRIVER_DIR}/org.postgresql/
  - mkdir -p ${DBEAVER_DRIVER_DIR}/net.postgis/
  - wget -nv https://repo1.maven.org/maven2/net/postgis/postgis-jdbc/{{dbeaver.drivers.postgis_jdbc}}/postgis-jdbc-{{dbeaver.drivers.postgis_jdbc}}.jar -P ${DBEAVER_DRIVER_DIR}/net.postgis/
  - wget -nv https://repo1.maven.org/maven2/net/postgis/postgis-jdbc/{{dbeaver.drivers.postgis_jdbc}}/postgis-jdbc-{{dbeaver.drivers.postgis_jdbc}}.pom -P ${DBEAVER_DRIVER_DIR}/net.postgis/
  - mv /opt/build/dbeaver_drivers_config.xml /usr/share/dbeaver/drivers-config.xml
  - echo "-Ddbeaver.drivers.configuration-file=/usr/share/dbeaver/drivers-config.xml" >> /usr/share/dbeaver/dbeaver.ini
  - echo "-Djava.security.auth.login.config=/etc/jaas.conf" >> /usr/share/dbeaver/dbeaver.ini
  - ls -alh ${DBEAVER_DRIVER_DIR}/*
  - echo "... successfully installed DBeaver drivers";
  # Install PyCharm
  - echo "Installing PyCharm..."
  - snap install pycharm-community --classic
  - PATH=$PATH:/snap/bin
  - if [ "$(which pycharm-community)" = "" ]; then echo "Could not install PyCharm!"; exit 1; else echo "... successfully installed PyCharm"; fi
  # Install RStudio,
  - echo "Installing RStudio..."
  - /opt/build/download_and_install_deb.sh rstudio
  - if [ "$(which rstudio)" = "" ]; then echo "Could not install RStudio!"; exit 1; else echo "... successfully installed RStudio"; fi
  # Install bats
  - echo "Installing bats..."
  - git clone https://github.com/bats-core/bats-core /opt/bats/bats-core
  - git clone https://github.com/bats-core/bats-support /opt/bats/bats-support
  - git clone https://github.com/bats-core/bats-assert /opt/bats/bats-assert
  - git clone https://github.com/bats-core/bats-file /opt/bats/bats-file
  - /opt/bats/bats-core/install.sh /usr/local
  - if [ "$(which bats)" = "" ]; then echo "Could not install bats!"; exit 1; else echo "... successfully installed bats"; fi
  # Install pyenv and pyenv-virtualenv
  - echo "Installing pyenv..."
  - export PYENV_ROOT="/opt/pyenv"
  - rm -rf $PYENV_ROOT 2> /dev/null
  - PATH="$PYENV_ROOT/bin:$PATH"  # NB. pyenv needs to be at the beginning of the path so that it can override other python versions
  - curl -s -S -L https://raw.githubusercontent.com/pyenv/pyenv-installer/master/bin/pyenv-installer | bash
  - if [ "$(which pyenv)" = "" ]; then echo "Could not install pyenv!"; exit 1; else echo "... successfully installed pyenv"; fi
  # Get icons for webapps
  - echo "Downloading icons..."
  - mkdir -p /opt/icons
  - wget https://cocalc.com/img/cocalc-icon.svg -O /tmp/cocalc-icon.svg
  - wget https://raw.githubusercontent.com/hackmdio/codimd/develop/public/favicon.png -O /opt/icons/codimd.png
  - wget https://about.gitlab.com/images/press/logo/png/gitlab-icon-rgb.png -O /opt/icons/gitlab.png
  - convert -density 983 -transparent white /tmp/cocalc-icon.svg /opt/icons/cocalc.png  # this should give a 1024x1024 png

  # Manually update ClamAV signature database
  - echo ">=== $(date +%s) Updating ClamAV database ===<"
  # We do not update ClamAV at build time since these definitions need to be updated at deployment times
  - systemctl stop clamav-freshclam
  - systemctl disable clamav-freshclam
  # As clamav-unofficial-sigs has not been updated since 2014, we need the following fixes:
  # Calls to SecuriteInfo fail with 'curl: (6) Could not resolve host: clamav.securiteinfo.com'
  # - disable this source as suggested here: https://bugs.launchpad.net/ubuntu/+source/clamav-unofficial-sigs/+bug/1643172
  - sed -i '/si_dbs=/,/^"$/d' /usr/share/clamav-unofficial-sigs/conf.d/00-clamav-unofficial-sigs.conf
  - sed -i '/si_update_hours/d' /usr/share/clamav-unofficial-sigs/conf.d/00-clamav-unofficial-sigs.conf
  # Calls to MalwarePatrol fail with 'MalwarePatrol mbl.ndb database integrity tested BAD - SKIPPING'
  # - disable this source as suggested here: https://www.mail-archive.com/pkg-clamav-devel@lists.alioth.debian.org/msg05014.html
  - sed -i '/mbl_dbs=/,/^"$/d' /usr/share/clamav-unofficial-sigs/conf.d/00-clamav-unofficial-sigs.conf
  # Update unofficial signatures (strangely this gives no output in the cloud-init logs)
  - clamav-unofficial-sigs 2>&1
  - clamav-unofficial-sigs -i

  # Install Spark and Hadoop - approximately 10 minutes
  - echo ">=== $(date +%s) Installing Spark/Hadoop ===<"
  - shui install --latest --target /opt
  - mv /opt/spark* /opt/spark
  - PATH=$PATH:/opt/spark/bin
  - if [ "$(which spark-shell)" = "" ]; then echo "Could not install Spark/Hadoop!"; exit 1; else echo "... successfully installed Spark/Hadoop"; fi

  # Install Julia and packages - approximately 20 minutes
  - echo ">=== $(date +%s) Installing Julia and packages ===<"
  - jill install stable --confirm --install_dir /opt/julia
  - JULIA_BASE_DIR=$(ls -d /opt/julia/julia*)
  - if [ "$(which julia)" = "" ]; then echo "Could not install Julia!"; exit 1; fi
  - export JULIA_PACKAGES="[\"$(sed '/^$/d' /opt/build/packages/packages-julia.list | paste -s -d '|' | sed 's/|/", "/g')\"]"
  # Create a global Julia depot for package installation
  - export JULIA_DEPOT_PATH="${JULIA_BASE_DIR}/depot/"
  - mkdir -p ${JULIA_DEPOT_PATH}
  - sed -i "/DEPOT_PATH/d" ${JULIA_BASE_DIR}/etc/julia/startup.jl
  - echo "push!(DEPOT_PATH, \"${JULIA_DEPOT_PATH}\")" >> ${JULIA_BASE_DIR}/etc/julia/startup.jl
  # Set some Julia environment variables before installing/building the packages
  - export JULIA_COPY_STACKS=1
  - export PYTHON="$(which python3)"  # link Julia against system Python 3
  - julia -e "using Pkg; Pkg.add($JULIA_PACKAGES); for package in $JULIA_PACKAGES; Pkg.build(package); end"
  # Move the locally-installed Julia kernel to the main directory
  - mv /root/.local/share/jupyter ${JULIA_BASE_DIR}/share || exit 1
  # Ensure that Julia depot is globally readable
  - chmod -R o=u,o-w ${JULIA_BASE_DIR}/depot/
  # Write Julia environment variables to global .bashrc
  - echo "export JULIA_COPY_STACKS=${JULIA_COPY_STACKS}" >> /etc/bash.bashrc
  - echo "export JULIA_DEPOT_PATH=~/.julia:${JULIA_DEPOT_PATH}" >> /etc/bash.bashrc  # ensure that each user's DEPOT_PATH will be the usual default (~/.julia) followed by the global depot
  - echo "export PYTHON=${PYTHON}" >> /etc/bash.bashrc
  # Check for missing packages
  - MISSING_JULIA_PACKAGES=$(julia -e "for package in $JULIA_PACKAGES; try; abspath(joinpath(dirname(Base.find_package(package)))); @eval using \$(Symbol(package)); catch e; println(package); end; end;")
  - if [ "$MISSING_JULIA_PACKAGES" ]; then echo "Could not install Julia packages - $MISSING_JULIA_PACKAGES"; exit 1; else echo "... successfully installed Julia"; fi

  # Install python versions
  - export PYTHON_VERSIONS="$(ls /opt/build/python-requirements-py*txt | rev | cut -d '-' -f 1 | rev | sed 's/py//; s/\.txt//')"
  - |
    for python_version in $PYTHON_VERSIONS; do
      # Create simple package list from requirements file
      sed 's/<.*//; s/=.*//; s/>.*//' /opt/build/python-requirements-py${python_version}.txt > /opt/build/packages/packages-python-pypi-${python_version}.list
      chmod 0444 /opt/build/packages/packages-python-pypi-${python_version}.list
      # Install python versions
      /opt/build/install_python_version.sh py${python_version} || exit 1
    done
  - echo "Installed python versions"
  - du --si -d 1 /opt/pyenv/versions
  # Add pyenv to global settings
  - echo "Configuring pyenv global settings"
  - echo '# Set up pyenv' >> /etc/bash.bashrc
  - echo "export PYENV_ROOT=\"$PYENV_ROOT\"" >> /etc/bash.bashrc
  - echo "PATH=\"$PYENV_ROOT/bin:$PATH\"" >> /etc/bash.bashrc
  - echo 'eval "$(pyenv init --path)"' >> /etc/bash.bashrc
  - echo 'eval "$(pyenv init - --no-rehash)"' >> /etc/bash.bashrc
  - echo 'eval "$(pyenv virtualenv-init -)"' >> /etc/bash.bashrc
  - echo "pyenv global $(ls /opt/pyenv/versions/ | sort -V | tail -n 1)" >> /etc/bash.bashrc
  # Make the global environment setting file live in each user's home directory
  - sed -i 's|PYENV_VERSION_FILE=.*|PYENV_VERSION_FILE=${HOME}/.pyenv_version|' /opt/pyenv/libexec/pyenv-global
  - sed -i 's|${PYENV_ROOT}/version|${HOME}/.pyenv_version|' /opt/pyenv/libexec/pyenv-version-file
  # To ensure site-packages can be used but not altered give 'other' the same permissions as 'owner' on the pyenv directory but remove write access
  # Finally, make the shims directory writeable so that users can create new shims
  - echo "Updating ${PYENV_ROOT} permissions"
  - chmod -R o=u,o-w ${PYENV_ROOT}
  - chmod go+w /opt/pyenv/shims

  # Install any missing R packages - approximately 40 minutes
  - echo ">=== $(date +%s) Installing R packages ===<"
  - export HOME=/root  # this is needed for the installation of the 'credentials' package
  - echo "export RSTUDIO_WHICH_R=/usr/bin/R" >> /etc/bash.bashrc  # this ensures that all users will pick up system R when running RStudio
  # Install CRAN packages and terminate if any are missing
  - export CRAN_PACKAGES="\"$(sed '/^$/d' /opt/build/packages/packages-r-cran.list | paste -s -d '|' | sed 's/|/", "/g')\""
  - echo "Preparing to install $(echo $CRAN_PACKAGES | wc -w) CRAN packages\n${CRAN_PACKAGES}"
  - Rscript -e "options('Ncpus' = parallel::detectCores()); requested_pkgs <- c($CRAN_PACKAGES); remaining_pkgs <- requested_pkgs[!(requested_pkgs %in% installed.packages()[,'Package'])]; if(length(remaining_pkgs)) { print(paste('Installing', paste(remaining_pkgs, collapse=', '))); install.packages(remaining_pkgs, quiet = TRUE) } else { print('No packages left to install') }"
  - MISSING_CRAN_PACKAGES=$(Rscript -e "requested_pkgs <- c($CRAN_PACKAGES); missing_pkgs <- requested_pkgs[!(requested_pkgs %in% installed.packages()[,'Package'])]; print(missing_pkgs)" | sed "s/character(0)//")
  - if [ "$MISSING_CRAN_PACKAGES" ]; then echo "Could not install CRAN packages\n${MISSING_CRAN_PACKAGES}"; exit 1; else echo "... successfully installed CRAN packages"; fi
  # Install BioConductor packages and terminate if any are missing
  - export BIOCONDUCTOR_PACKAGES="\"$(sed '/^$/d' /opt/build/packages/packages-r-bioconductor.list | paste -s -d '|' | sed 's/|/", "/g')\""
  - echo "Preparing to install $(echo $BIOCONDUCTOR_PACKAGES | wc -w) BioConductor packages\n${BIOCONDUCTOR_PACKAGES}"
  - Rscript -e "options('Ncpus' = parallel::detectCores()); requested_pkgs <- c($BIOCONDUCTOR_PACKAGES); remaining_pkgs <- requested_pkgs[!(requested_pkgs %in% installed.packages()[,'Package'])]; if(length(remaining_pkgs)) { print(paste('Installing', paste(remaining_pkgs, collapse=', '))); BiocManager::install(remaining_pkgs, quiet = TRUE) } else { print('No packages left to install') }"
  - MISSING_BIOCONDUCTOR_PACKAGES=$(Rscript -e "requested_pkgs <- c($BIOCONDUCTOR_PACKAGES); missing_pkgs <- requested_pkgs[!(requested_pkgs %in% installed.packages()[,'Package'])]; print(missing_pkgs)" | sed "s/character(0)//")
  - if [ "$MISSING_BIOCONDUCTOR_PACKAGES" ]; then echo "Could not install Bioconductor packages\n${MISSING_BIOCONDUCTOR_PACKAGES}"; exit 1; else echo "... successfully installed BioConductor packages"; fi

  # Configure jupyter kernels
  - echo ">=== $(date +%s) Configuring Jupyter with Julia, Python and R kernels ===<"
  # Mark the system kernel as not to be used
  - |
    sed -i "s|\"display_name\":.*Python.*|\"display_name\": \"System Python - do not use\",|" /usr/share/jupyter/kernels/python3/kernel.json
  # Add the Julia kernel
  - jupyter kernelspec install ${JULIA_BASE_DIR}/share/jupyter/kernels/julia-* || exit 1
  # Add the python kernels
  - |
    for python_version in $PYTHON_VERSIONS; do
      jupyter kernelspec install /opt/pyenv/versions/*/share/jupyter/kernels/py${python_version} || exit 1
    done
  # Add the R kernel
  - R_VERSION=$(R --version | head -n 1 | cut -d ' ' -f3)
  - ln -s /usr/local/lib/R/site-library/IRkernel/kernelspec /usr/local/lib/R/site-library/IRkernel/R${R_VERSION}
  - |
    sed -i "s|\"display_name\":.*\R.*|\"display_name\": \"R ${R_VERSION}\",|" /usr/local/lib/R/site-library/IRkernel/kernelspec/kernel.json
  - jupyter kernelspec install /usr/local/lib/R/site-library/IRkernel/R${R_VERSION} || exit 1
  # Log the output kernels
  - echo "Checking installed Jupyter kernels"
  - jupyter kernelspec list

  # Clean up any build artifacts
  - echo ">=== $(date +%s) Cleaning up the build environment ===<"
  - USED_BYTES_OLD=$(df / | tail -n 1 | awk '{printf $3}')
  - find /root/ -mindepth 1 -delete  # remove all files from root's home directory
  - tmpreaper 10m /tmp/ /var/tmp/    # remove temporary files that have not been accessed in 10 minutes
  # Remove netcat (potential security issue) [Note this will remove the 'ubuntu-minimal' metapackage but does not remove any other real packages]
  # Remove xscreensaver (unnecessary)
  - apt-get remove -y netcat-openbsd xscreensaver
  # Remove any unused auto-installed packages
  - apt-get autoclean -y
  - apt-get autoremove -y --purge
  - apt-get clean
  # Log space saved
  - USED_BYTES_NEW=$(df / | tail -n 1 | awk '{printf $3}')
  - echo "Successfully reclaimed $(numfmt --to=iec-i --suffix=B $(($USED_BYTES_OLD - $USED_BYTES_NEW))) of disk space"

  # Check for successful installations
  - echo ">=== $(date +%s) Checking environment configuration ===<"
  # Set PATH to the current working version which contains all installed packages
  # Also add ~/.local/bin and ~/bin so that any executables that are installed there (eg. by pip) can be used
  # We do this at the end of the script so that
  # - we know this is the PATH that worked when we checked for each package
  # - we only get one entry in /etc/bash.bashrc rather than several with "last-one-wins"
  - PATH="$PATH:\$HOME/.local/bin:\$HOME/bin"
  - echo "Setting PATH to '${PATH}'"
  - if [ ! "$(grep ^PATH= /etc/bash.bashrc)" ]; then echo "PATH=" >> /etc/bash.bashrc; fi
  - sed -i "s|^PATH=.*|export PATH=${PATH}|" /etc/bash.bashrc
  # Run installation tests
  - python3 /opt/build/check_installation.py || exit 1

final_message: "System setup through cloud-init is finished. Configuration took $UPTIME seconds"

# Shutdown at the end of the job to save on running costs
power_state:
  mode: poweroff
  message: "Shutting down after cloud-init is finished"
  timeout: 30
  condition: true
