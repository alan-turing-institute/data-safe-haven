#cloud-config

# Update package database on first boot
package_update: true

# Upgrade installed packages on first boot
package_upgrade: true

apt:
  # Append to the existing /etc/apt/sources.list
  preserve_sources_list: true

  # Add repositories
  sources:
    atom.list:
      source: "deb https://packagecloud.io/AtomEditor/atom/any/ any main"
      keyid: 0A0FAB860D48560332EFB581B75442BBDE9E3B09  # https://packagecloud.io/AtomEditor/atom (https://packagecloud.io/docs#gpg_signing) <support@packagecloud.io>

    # Official DBeaver PPA (from https://dbeaver.io/download/)
    dbeaver.list:
      source: "deb http://ppa.launchpad.net/serge-rider/dbeaver-ce/ubuntu focal main"
      keyid: 30ECE32520D438C21E16BF884A71B51882788FD2  # Launchpad PPA for Serge Rider

    microsoft-general.list:
      source: "deb https://packages.microsoft.com/ubuntu/20.04/prod focal main"
      keyid: BC528686B50D79E339D3721CEB3E94ADBE1229CF  # Microsoft (Release signing) <gpgsecurity@microsoft.com>

    mono-project.list:
      source: "deb https://download.mono-project.com/repo/ubuntu stable-focal main"
      keyid: 3FA7E0328081BFF6A14DA29AA6A19B38D3D831EF  # Xamarin Public Jenkins (auto-signing) <releng@xamarin.com>

    nvidia-cuda.list:
      source: "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64 /"
      keyid: AE09FE4BBD223A84B2CCFCE3F60F4B3D7FA2AF80  # cudatools <cudatools@nvidia.com>

    nvidia-ml-1804.list:
      source: "deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 /"
      keyid: AE09FE4BBD223A84B2CCFCE3F60F4B3D7FA2AF80  # cudatools <cudatools@nvidia.com>

    nvidia-ml-2004.list:
      source: "deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64 /"
      keyid: AE09FE4BBD223A84B2CCFCE3F60F4B3D7FA2AF80  # cudatools <cudatools@nvidia.com>

    postgresql.list:
      source: "deb http://apt.postgresql.org/pub/repos/apt/ focal-pgdg main"
      keyid: B97B0AFCAA1A47F044F244A07FCC7D46ACCC4CF8  # PostgreSQL Debian Repository

    qgis.list:
      source: "deb https://qgis.org/ubuntu focal main"
      keyid: 39877635093F2656019711FAF7E06F06199EF2F2  # QGIS Archive Automatic Signing Key (2020) <qgis-developer@lists.osgeo.org>

    rproject-updates.list:
      source: "deb https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/"
      keyid: E298A3A825C0D65DFD57CBB651716619E084DAB9  # Michael Rutter <marutter@gmail.com>

    sbt.list:
      source: "deb https://dl.bintray.com/sbt/debian /"
      keyid: 2EE0EA64E40A89B84B2DF73499E82A75642AC823  # sbt build tool <scalasbt@gmail.com>

    vscode.list:
      source: "deb https://packages.microsoft.com/repos/vscode stable main"
      keyid: BC528686B50D79E339D3721CEB3E94ADBE1229CF  # Microsoft (Release signing) <gpgsecurity@microsoft.com>


write_files:
  - path: "/etc/jaas.conf"
    owner: root:root
    permissions: "0444"
    content: |
      pgjdbc {
      com.sun.security.auth.module.Krb5LoginModule required
          useTicketCache=true
          debug=true
          renewTGT=true
          doNotPrompt=true;
      };
  # NB. the URL contains the commit this release was made from
  - path: "/opt/build/azuredatastudio.debinfo"
    permissions: "0400"
    content: |
      hash: 063ef01c23fbcab4a34d18c0acf0e504ecda03f80e3502761945075ec87f1102
      version: 1.26.1
      debfile: azuredatastudio-linux-|VERSION|.deb
      remote: https://sqlopsbuilds.azureedge.net/stable/796abbdf5fdd341e3528e30a6b777c93e115eb02/|DEBFILE|
  - path: "/opt/build/rstudio.debinfo"
    permissions: "0400"
    content: |
      hash: 3b5d38351d27868b1829b07471c0f5d883c0b1449e682634029a57afb96539a8
      version: 1.4.1106
      debfile: rstudio-|VERSION|-amd64.deb
      remote: https://download1.rstudio.org/desktop/bionic/amd64/|DEBFILE|
  - path: "/opt/verification/analyse_build.py"
    permissions: "0755"
    content: |
      <analyse_build.py>
  - path: "/opt/build/install_python_version.sh"
    permissions: "0500"
    content: |
      <install_python_version.sh>
  - path: "/opt/build/dbeaver_drivers_config.xml"
    permissions: "0444"
    content: |
      <dbeaver_drivers_config.xml>
  - path: "/opt/build/deprovision.log"
    permissions: "0600"
    content: |
      # Deprovisioning log
  - path: "/opt/build/deprovision_vm.sh"
    permissions: "0500"
    content: |
      <deprovision_vm.sh>
  - path: "/opt/build/download_and_install_deb.sh"
    permissions: "0500"
    content: |
      <download_and_install_deb.sh>
  - path: "/opt/build/packages/packages-julia.list"
    permissions: "0444"
    content: |
      <packages-julia.list>
  - path: "/opt/build/packages/packages-r-bioconductor.list"
    permissions: "0444"
    content: |
      <packages-r-bioconductor.list>
  - path: "/opt/build/packages/packages-r-cran.list"
    permissions: "0444"
    content: |
      <packages-r-cran.list>
  - path: "/opt/build/performance_log.csv"
    permissions: "0644"
    content: |
      # Performance log
  - path: "/opt/build/python-requirements-py36.txt"
    permissions: "0444"
    content: |
      <python-requirements-py36.txt>
  - path: "/opt/build/python-requirements-py37.txt"
    permissions: "0444"
    content: |
      <python-requirements-py37.txt>
  - path: "/opt/build/python-requirements-py38.txt"
    permissions: "0444"
    content: |
      <python-requirements-py38.txt>
  - path: "/opt/build/python-pyproject-template.toml"
    permissions: "0400"
    content: |
      [tool.poetry]
      name = "<PYTHON_ENV_NAME>"
      version = "1.0.0"
      description = "<PYTHON_ENV_NAME>"
      authors = ["ROOT <root@localhost>"]

      [tool.poetry.dependencies]
      python = "<PYTHON_VERSION>"
  - path: "/opt/build/python-system-packages.txt"
    permissions: "0444"
    content: |
      jill       # for installing Julia
      matplotlib # for PyPlot Julia package
      shui       # for installing Spark/Hadoop
  - path: "/usr/share/applications/jupyter-notebook.desktop"
    permissions: "0644"
    content: |
      [Desktop Entry]
      Version=1.0
      Type=Application
      Name=Jupyter Notebook
      Exec=jupyter notebook
      Icon=/usr/lib/python3/dist-packages/notebook/static/base/images/favicon.ico
      Categories=Utility;TextEditor;Development;IDE;
  - path: "/usr/share/applications/pycharm.desktop"
    permissions: "0644"
    content: |
      [Desktop Entry]
      Version=1.0
      Type=Application
      Name=PyCharm
      Exec=/snap/bin/pycharm-community
      Icon=/snap/pycharm-community/current/meta/gui/icon.png
      Categories=Utility;TextEditor;Development;IDE;

# List of packages to install with apt-get
packages:
  - <apt packages>

# Set locale and timezone
locale: en_GB.UTF-8
timezone: <timezone>

# Set the NTP server
# By default we use Google's NTP servers which are incompatible with other servers due to leap-second smearing
ntp:
  pools:
    - <ntp-server>

# List of commands to run using `/bin/sh`
# When changing these lines try to ensure that everything is checked as close as possible to the point when it is installed/configured.
# If any of the installation/configuration checks fail then end the cloud-init process immediately by calling `exit 1`.
# This allows us to (i) not waste time completing a build once a step has failed and (ii) easily tell when and why a build failed using the analyse_build.py script.
runcmd:
  # Log system performance during the installation and record it each minute
  - nohup dstat --mem --cpu --time --output /opt/verification/performance_log.csv 60 > /dev/null &
  # Suppress apt prompts and warning messages
  - echo "Suppressing apt prompts"
  - export DEBIAN_FRONTEND=noninteractive
  - sleep 1  # ensure that run commands are cleanly time-separated from other cloud-init commands

  - echo ">=== $(date +%s) Installing additional deb/snap/source packages ===<"
  # Install python packages used in the rest of the build
  - pip3 install -r /opt/build/python-system-packages.txt
  # NVidia setup (necessary packages from https://www.tensorflow.org/install/gpu are in our apt install list)
  - echo "Checking NVidia requirements for tensorflow..."
  - if [ "$(which nvidia-smi)" = "" ]; then echo "Could not install NVidia tools!"; exit 1; else echo "... successfully installed NVidia requirements"; fi
  # Microsoft ODBC tools
  - echo "Installing Microsoft ODBC tools..."
  - ACCEPT_EULA=Y apt-get install -y msodbcsql17 mssql-tools
  - PATH=$PATH:/opt/mssql-tools/bin
  - if [ "$(which sqlcmd)" = "" ]; then echo "Could not install Microsoft ODBC tools!"; exit 1; else echo "... successfully installed Microsoft ODBC tools"; fi
  # Azure Data Studio
  - echo "Installing Azure Data Studio..."
  - /opt/build/download_and_install_deb.sh azuredatastudio
  - if [ "$(which azuredatastudio)" = "" ]; then echo "Could not install Azure Data Studio!"; exit 1; else echo "... successfully installed Azure Data Studio"; fi
  # DBeaver and drivers
  - echo "Installing DBeaver..."
  - if [ "$(which dbeaver)" = "" ]; then echo "Could not install DBeaver!"; exit 1; else echo "... successfully installed DBeaver"; fi
  # Install drivers from maven
  - echo "Installing DBeaver drivers..."
  - DBEAVER_DRIVER_DIR="/usr/share/dbeaver/drivers/maven/maven-central"
  - MSSQL_JDBC_VERSION="9.2.0.jre8"
  - PGJDBC_VERSION="1.1.6"
  - POSTGIS_JDBC_VERSION="2.5.0"
  - POSTGRESQL_VERSION="42.2.9"
  # Note that the filenames specified here have to be kept synchronised with the names in the dbeaver_drivers_config.xml file.
  # Adding new drivers therefore involves changing both this file and the XML file.
  - mkdir -p ${DBEAVER_DRIVER_DIR}/com.microsoft.sqlserver/
  - wget -nv https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/${MSSQL_JDBC_VERSION}/mssql-jdbc-${MSSQL_JDBC_VERSION}.jar -P ${DBEAVER_DRIVER_DIR}/com.microsoft.sqlserver/
  - wget -nv https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/${MSSQL_JDBC_VERSION}/mssql-jdbc-${MSSQL_JDBC_VERSION}.pom -P ${DBEAVER_DRIVER_DIR}/com.microsoft.sqlserver/
  - mkdir -p ${DBEAVER_DRIVER_DIR}/org.postgresql/
  - wget -nv https://repo1.maven.org/maven2/org/postgresql/pgjdbc-core-parent/${PGJDBC_VERSION}/pgjdbc-core-parent-${PGJDBC_VERSION}.pom -P ${DBEAVER_DRIVER_DIR}/org.postgresql/
  - wget -nv https://repo1.maven.org/maven2/org/postgresql/pgjdbc-versions/${PGJDBC_VERSION}/pgjdbc-versions-${PGJDBC_VERSION}.pom -P ${DBEAVER_DRIVER_DIR}/org.postgresql/
  - wget -nv https://repo1.maven.org/maven2/org/postgresql/postgresql/${POSTGRESQL_VERSION}/postgresql-${POSTGRESQL_VERSION}.jar -P ${DBEAVER_DRIVER_DIR}/org.postgresql/
  - wget -nv https://repo1.maven.org/maven2/org/postgresql/postgresql/${POSTGRESQL_VERSION}/postgresql-${POSTGRESQL_VERSION}.pom -P ${DBEAVER_DRIVER_DIR}/org.postgresql/
  - mkdir -p ${DBEAVER_DRIVER_DIR}/net.postgis/
  - wget -nv https://repo1.maven.org/maven2/net/postgis/postgis-jdbc/${POSTGIS_JDBC_VERSION}/postgis-jdbc-${POSTGIS_JDBC_VERSION}.jar -P ${DBEAVER_DRIVER_DIR}/net.postgis/
  - wget -nv https://repo1.maven.org/maven2/net/postgis/postgis-jdbc/${POSTGIS_JDBC_VERSION}/postgis-jdbc-${POSTGIS_JDBC_VERSION}.pom -P ${DBEAVER_DRIVER_DIR}/net.postgis/
  # Expand driver configuration template
  - sed -i "s/|POSTGRESQL_VERSION|/${POSTGRESQL_VERSION}/g" /opt/build/dbeaver_drivers_config.xml
  - sed -i "s/|MSSQL_JDBC_VERSION|/${MSSQL_JDBC_VERSION}/g" /opt/build/dbeaver_drivers_config.xml
  - sed -i "s/|POSTGIS_JDBC_VERSION|/${POSTGIS_JDBC_VERSION}/g" /opt/build/dbeaver_drivers_config.xml
  - mv /opt/build/dbeaver_drivers_config.xml /usr/share/dbeaver/drivers-config.xml
  - echo "-Ddbeaver.drivers.configuration-file=/usr/share/dbeaver/drivers-config.xml" >> /usr/share/dbeaver/dbeaver.ini
  - echo "-Djava.security.auth.login.config=/etc/jaas.conf" >> /usr/share/dbeaver/dbeaver.ini
  - ls -alh ${DBEAVER_DRIVER_DIR}/*
  - echo "... successfully installed DBeaver drivers";
  # Install PyCharm
  - echo "Installing PyCharm..."
  - snap install pycharm-community --classic
  - PATH=$PATH:/snap/bin
  - if [ "$(which pycharm-community)" = "" ]; then echo "Could not install PyCharm!"; exit 1; else echo "... successfully installed PyCharm"; fi
  # Install RStudio,
  - echo "Installing RStudio..."
  - /opt/build/download_and_install_deb.sh rstudio
  - if [ "$(which rstudio)" = "" ]; then echo "Could not install RStudio!"; exit 1; else echo "... successfully installed RStudio"; fi
  # Install bats
  - echo "Installing bats..."
  - git clone https://github.com/bats-core/bats-core /opt/bats/bats-core
  - git clone https://github.com/bats-core/bats-support /opt/bats/bats-support
  - git clone https://github.com/bats-core/bats-assert /opt/bats/bats-assert
  - git clone https://github.com/bats-core/bats-file /opt/bats/bats-file
  - /opt/bats/bats-core/install.sh /usr/local
  - if [ "$(which bats)" = "" ]; then echo "Could not install bats!"; exit 1; else echo "... successfully installed bats"; fi
  # Install pyenv and pyenv-virtualenv
  - echo "Installing pyenv..."
  - export PYENV_ROOT="/opt/pyenv"
  - rm -rf $PYENV_ROOT 2> /dev/null
  - PATH="$PYENV_ROOT/bin:$PATH"  # NB. pyenv needs to be at the beginning of the path so that it can override other python versions
  - curl -s -S -L https://raw.githubusercontent.com/pyenv/pyenv-installer/master/bin/pyenv-installer | bash
  - if [ "$(which pyenv)" = "" ]; then echo "Could not install pyenv!"; exit 1; else echo "... successfully installed pyenv"; fi

  # Manually update ClamAV signature database
  - echo ">=== $(date +%s) Updating ClamAV database ===<"
  # We do not update ClamAV at build time since these definitions need to be updated at deployment times
  - systemctl stop clamav-freshclam
  - systemctl disable clamav-freshclam
  # As clamav-unofficial-sigs has not been updated since 2014, we need the following fixes:
  # Calls to SecuriteInfo fail with 'curl: (6) Could not resolve host: clamav.securiteinfo.com'
  # - disable this source as suggested here: https://bugs.launchpad.net/ubuntu/+source/clamav-unofficial-sigs/+bug/1643172
  - sed -i '/si_dbs=/,/^"$/d' /usr/share/clamav-unofficial-sigs/conf.d/00-clamav-unofficial-sigs.conf
  - sed -i '/si_update_hours/d' /usr/share/clamav-unofficial-sigs/conf.d/00-clamav-unofficial-sigs.conf
  # Calls to MalwarePatrol faile with 'MalwarePatrol mbl.ndb database integrity tested BAD - SKIPPING'
  # - disable this source as suggested here: https://www.mail-archive.com/pkg-clamav-devel@lists.alioth.debian.org/msg05014.html
  - sed -i '/mbl_dbs=/,/^"$/d' /usr/share/clamav-unofficial-sigs/conf.d/00-clamav-unofficial-sigs.conf
  # Update unofficial signatures (strangely this gives no output in the cloud-init logs)
  - clamav-unofficial-sigs 2>&1
  - clamav-unofficial-sigs -i

  # Install Spark and Hadoop - approximately 10 minutes
  - echo ">=== $(date +%s) Installing Spark/Hadoop ===<"
  - shui install --latest --target /opt/spark
  - SPARK_BASE_DIR=$(ls -d /opt/spark/spark*)
  - PATH=$PATH:${SPARK_BASE_DIR}/bin
  - if [ "$(which spark-shell)" = "" ]; then echo "Could not install Spark/Hadoop!"; exit 1; else echo "... successfully installed Spark/Hadoop"; fi

  # Install Julia and packages - approximately 20 minutes
  - echo ">=== $(date +%s) Installing Julia and packages ===<"
  - jill install stable --confirm --install_dir /opt/julia
  - JULIA_BASE_DIR=$(ls -d /opt/julia/julia*)
  - if [ "$(which julia)" = "" ]; then echo "Could not install Julia!"; exit 1; fi
  - export JULIA_PACKAGES="[\"$(sed '/^$/d' /opt/build/packages/packages-julia.list | paste -s -d '|' | sed 's/|/", "/g')\"]"
  # Create a global Julia depot for package installation
  - export JULIA_DEPOT_PATH="${JULIA_BASE_DIR}/depot/"
  - mkdir -p ${JULIA_DEPOT_PATH}
  - sed -i "/DEPOT_PATH/d" ${JULIA_BASE_DIR}/etc/julia/startup.jl
  - echo "push!(DEPOT_PATH, \"${JULIA_DEPOT_PATH}\")" >> ${JULIA_BASE_DIR}/etc/julia/startup.jl
  # Set some Julia environment variables before installing/building the packages
  - export JULIA_COPY_STACKS=1
  - export PYTHON="$(which python3)"  # link Julia against system Python 3
  - julia -e "using Pkg; Pkg.add($JULIA_PACKAGES); for package in $JULIA_PACKAGES; Pkg.build(package); end"
  # Move the locally-installed Julia kernel to the main directory
  - mv /root/.local/share/jupyter ${JULIA_BASE_DIR}/share || exit 1
  # Ensure that Julia depot is globally readable
  - chmod -R o=u,o-w ${JULIA_BASE_DIR}/depot/
  # Write Julia environment variables to global .bashrc
  - echo "export JULIA_COPY_STACKS=${JULIA_COPY_STACKS}" >> /etc/bash.bashrc
  - echo "export JULIA_DEPOT_PATH=~/.julia:${JULIA_DEPOT_PATH}" >> /etc/bash.bashrc  # ensure that each user's DEPOT_PATH will be the usual default (~/.julia) followed by the global depot
  - echo "export PYTHON=${PYTHON}" >> /etc/bash.bashrc
  # Check for missing packages
  - MISSING_JULIA_PACKAGES=$(julia -e "for package in $JULIA_PACKAGES; try; abspath(joinpath(dirname(Base.find_package(package)))); @eval using \$(Symbol(package)); catch e; println(package); end; end;")
  - if [ "$MISSING_JULIA_PACKAGES" ]; then echo "Could not install Julia packages - $MISSING_JULIA_PACKAGES"; exit 1; else echo "... successfully installed Julia"; fi

  # Install python versions
  - export PYTHON_VERSIONS="$(ls /opt/build/python-requirements-py*txt | rev | cut -d '-' -f 1 | rev | sed 's/py//; s/\.txt//')"
  - |
    for python_version in $PYTHON_VERSIONS; do
      # Create simple package list from requirements file
      sed 's/<.*//; s/=.*//; s/>.*//' /opt/build/python-requirements-py${python_version}.txt > /opt/build/packages/packages-python-pypi-${python_version}.list
      chmod 0444 /opt/build/packages/packages-python-pypi-${python_version}.list
      # Install python versions
      /opt/build/install_python_version.sh py${python_version} || exit 1
    done
  - echo "Installed python versions"
  - du --si -d 1 /opt/pyenv/versions
  # Add pyenv to global settings
  - echo "Configuring pyenv global settings"
  - echo '# Set up pyenv' >> /etc/bash.bashrc
  - echo "export PYENV_ROOT=\"$PYENV_ROOT\"" >> /etc/bash.bashrc
  - echo "PATH=\"$PYENV_ROOT/bin:$PATH\"" >> /etc/bash.bashrc
  - echo 'eval "$(pyenv init - --no-rehash)"' >> /etc/bash.bashrc
  - echo 'eval "$(pyenv virtualenv-init -)"' >> /etc/bash.bashrc
  - echo "pyenv global $(ls /opt/pyenv/versions/ | sort -V | tail -n 1)" >> /etc/bash.bashrc
  # Make the global environment setting file live in each user's home directory
  - sed -i 's|PYENV_VERSION_FILE=.*|PYENV_VERSION_FILE=${HOME}/.pyenv_version|' /opt/pyenv/libexec/pyenv-global
  - sed -i 's|${PYENV_ROOT}/version|${HOME}/.pyenv_version|' /opt/pyenv/libexec/pyenv-version-file
  # To ensure site-packages can be used but not altered give 'other' the same permissions as 'owner' on the pyenv directory but remove write access
  # Finally, make the shims directory writeable so that users can create new shims
  - echo "Updating ${PYENV_ROOT} permissions"
  - chmod -R o=u,o-w ${PYENV_ROOT}
  - chmod go+w /opt/pyenv/shims

  # Install any missing R packages - approximately 1 hr
  - echo ">=== $(date +%s) Installing R packages ===<"
  - export HOME=/root  # this is needed for the installation of the 'credentials' package
  - echo "export RSTUDIO_WHICH_R=/usr/bin/R" >> /etc/bash.bashrc  # this ensures that all users will pick up system R when running RStudio
  # Install CRAN packages and terminate if any are missing
  - export CRAN_PACKAGES="\"$(sed '/^$/d' /opt/build/packages/packages-r-cran.list | paste -s -d '|' | sed 's/|/", "/g')\""
  - echo "Preparing to install $(echo $CRAN_PACKAGES | wc -w) CRAN packages\n${CRAN_PACKAGES}"
  - Rscript -e "options('Ncpus' = parallel::detectCores()); requested_pkgs <- c($CRAN_PACKAGES); remaining_pkgs <- requested_pkgs[!(requested_pkgs %in% installed.packages()[,'Package'])]; if(length(remaining_pkgs)) { print(paste('Installing', paste(remaining_pkgs, collapse=', '))); install.packages(remaining_pkgs, quiet = TRUE) } else { print('No packages left to install') }"
  - MISSING_CRAN_PACKAGES=$(Rscript -e "requested_pkgs <- c($CRAN_PACKAGES); missing_pkgs <- requested_pkgs[!(requested_pkgs %in% installed.packages()[,'Package'])]; print(missing_pkgs)" | sed "s/character(0)//")
  - if [ "$MISSING_CRAN_PACKAGES" ]; then echo "Could not install CRAN packages\n${MISSING_CRAN_PACKAGES}"; exit 1; else echo "... successfully installed CRAN packages"; fi
  # Install BioConductor packages and terminate if any are missing
  - export BIOCONDUCTOR_PACKAGES="\"$(sed '/^$/d' /opt/build/packages/packages-r-bioconductor.list | paste -s -d '|' | sed 's/|/", "/g')\""
  - echo "Preparing to install $(echo $BIOCONDUCTOR_PACKAGES | wc -w) BioConductor packages\n${BIOCONDUCTOR_PACKAGES}"
  - Rscript -e "options('Ncpus' = parallel::detectCores()); requested_pkgs <- c($BIOCONDUCTOR_PACKAGES); remaining_pkgs <- requested_pkgs[!(requested_pkgs %in% installed.packages()[,'Package'])]; if(length(remaining_pkgs)) { print(paste('Installing', paste(remaining_pkgs, collapse=', '))); BiocManager::install(remaining_pkgs, quiet = TRUE) } else { print('No packages left to install') }"
  - MISSING_BIOCONDUCTOR_PACKAGES=$(Rscript -e "requested_pkgs <- c($BIOCONDUCTOR_PACKAGES); missing_pkgs <- requested_pkgs[!(requested_pkgs %in% installed.packages()[,'Package'])]; print(missing_pkgs)" | sed "s/character(0)//")
  - if [ "$MISSING_BIOCONDUCTOR_PACKAGES" ]; then echo "Could not install Bioconductor packages\n${MISSING_BIOCONDUCTOR_PACKAGES}"; exit 1; else echo "... successfully installed BioConductor packages"; fi

  # Configure jupyter kernels
  - echo ">=== $(date +%s) Configuring Jupyter with Julia, Python and R kernels ===<"
  # Mark the system kernel as not to be used
  - |
    sed -i "s|\"display_name\":.*Python.*|\"display_name\": \"System Python - do not use\",|" /usr/share/jupyter/kernels/python3/kernel.json
  # Add the Julia kernel
  - jupyter kernelspec install ${JULIA_BASE_DIR}/share/jupyter/kernels/julia-* || exit 1
  # Add the python kernels
  - |
    for python_version in $PYTHON_VERSIONS; do
      jupyter kernelspec install /opt/pyenv/versions/*/share/jupyter/kernels/py${python_version} || exit 1
    done
  # Add the R kernel
  - R_VERSION=$(R --version | head -n 1 | cut -d ' ' -f3)
  - ln -s /usr/local/lib/R/site-library/IRkernel/kernelspec /usr/local/lib/R/site-library/IRkernel/R${R_VERSION}
  - |
    sed -i "s|\"display_name\":.*\R.*|\"display_name\": \"R ${R_VERSION}\",|" /usr/local/lib/R/site-library/IRkernel/kernelspec/kernel.json
  - jupyter kernelspec install /usr/local/lib/R/site-library/IRkernel/R${R_VERSION} || exit 1
  # Log the output kernels
  - echo "Checking installed Jupyter kernels"
  - jupyter kernelspec list

  # Clean up any build artifacts
  - echo ">=== $(date +%s) Cleaning up the build environment ===<"
  - USED_BYTES_OLD=$(df / | tail -n 1 | awk '{printf $3}')
  - find /root/ -mindepth 1 -delete  # remove all files from root's home directory
  - tmpreaper 10m /tmp/ /var/tmp/    # remove temporary files that have not been accessed in 10 minutes
  # Remove netcat (potential security issue) [Note this will remove the 'ubuntu-minimal' metapackage but does not remove any other real packages]
  # Remove xscreensaver (unnecessary)
  - apt-get remove -y netcat-openbsd xscreensaver
  # Remove any unused auto-installed packages
  - apt-get autoclean -y
  - apt-get autoremove -y --purge
  - apt-get clean
  # Log space saved
  - USED_BYTES_NEW=$(df / | tail -n 1 | awk '{printf $3}')
  - echo "Successfully reclaimed $(numfmt --to=iec-i --suffix=B $(($USED_BYTES_OLD - $USED_BYTES_NEW))) of disk space"

  # Check for successful installations
  - echo ">=== $(date +%s) Checking environment configuration ===<"
  # Set PATH to the current working version which contains all installed packages
  # Also add ~/.local/bin and ~/bin so that any executables that are installed there (eg. by pip) can be used
  # We do this at the end of the script so that
  # - we know this is the PATH that worked when we checked for each package
  # - we only get one entry in /etc/bash.bashrc rather than several with "last-one-wins"
  - PATH="$PATH:\$HOME/.local/bin:\$HOME/bin"
  - echo "Setting PATH to '${PATH}'"
  - if [ ! "$(grep ^PATH= /etc/bash.bashrc)" ]; then echo "PATH=" >> /etc/bash.bashrc; fi
  - sed -i "s|^PATH=.*|export PATH=${PATH}|" /etc/bash.bashrc
  # Programming languages
  - echo "\n... Programming languages:\n"
  - if [ "$(which dotnet)" ]; then echo "\n\n*dotnet*\n\n$(which dotnet)\n$(dotnet --version)"; else echo "ERROR dotnet not found!"; exit 1; fi
  - if [ "$(which g++)" ]; then echo "\n\n*g++*\n\n$(which g++)\n$(g++ --version)"; else echo "ERRO g++ not found!"; exit 1; fi
  - if [ "$(which gcc)" ]; then echo "\n\n*gcc*\n\n$(which gcc)\n$(gcc --version)"; else echo "ERROR gcc not found!"; exit 1; fi
  - if [ "$(which gfortran)" ]; then echo "\n\n*gfortran*\n\n$(which gfortran)\n$(gfortran --version)"; else echo "ERROR gfortran not found!"; exit 1; fi
  - if [ "$(which java)" ]; then echo "\n\n*java*\n\n$(which java)\n$(java -version)"; else echo "ERROR java not found!"; exit 1; fi
  - if [ "$(which julia)" ]; then echo "\n\n*julia*\n\n$(which julia)\n$(julia --version)"; else echo "ERROR Julia not found!"; exit 1; fi
  - if [ "$(which R)" ]; then echo "\n\n*R*\n\n$(which R)\n$(R --version)"; else echo "ERROR R not found!"; exit 1; fi
  - if [ "$(which scala)" ]; then echo "\n\n*scala*\n\n$(which scala)\n$(scalac -version)"; else echo "ERROR scala not found!"; exit 1; fi
  - if [ "$(which spark-shell)" ]; then echo "\n\n*R*\n\n$(which spark-shell)\n$(spark-shell --version)"; else echo "ERROR spark-shell not found!"; exit 1; fi
  # Editors
  - echo "\n... Editors/IDEs:\n"
  - if [ "$(which atom)" ]; then echo "\n\n*atom*\n\n$(which atom)\n$(dpkg -s atom | grep '^Version:')"; else echo "ERROR atom not found!"; exit 1; fi
  - if [ "$(which code)" ]; then echo "\n\n*code*\n\n$(which code)\n$(code --version)"; else echo "ERROR code not found!"; exit 1; fi
  - if [ "$(which emacs)" ]; then echo "\n\n*emacs*\n\n$(which emacs)\n$(emacs --version)"; else echo "ERROR emacs not found!"; exit 1; fi
  - if [ "$(which nano)" ]; then echo "\n\n*nano*\n\n$(which nano)\n$(nano --version)"; else echo "ERROR nano not found!"; exit 1; fi
  - if [ "$(which pycharm-community)" ]; then echo "\n\n*pycharm*\n\n$(which pycharm-community)\n$(snap list pycharm-community)"; else echo "ERROR PyCharm not found!"; exit 1; fi
  - if [ "$(which rstudio)" ]; then echo "\n\n*RStudio*\n\n$(which rstudio)\n$(dpkg -s rstudio | grep '^Version:')"; else echo "ERROR RStudio not found!"; fi
  - if [ "$(which vim)" ]; then echo "\n\n*vim*\n\n$(which vim)\n$(vim --version | grep '^VIM')"; else echo "ERROR vim not found!"; exit 1; fi
  # Presentation tools
  - echo "\n... Presentation tools:\n"
  - if [ "$(which latex)" ]; then echo "\n\n*latex*\n\n$(which latex)\n$(latex --version | grep 'TeX Live')"; else echo "ERROR latex not found!"; exit 1; fi
  - if [ "$(which libreoffice)" ]; then echo "\n\n*libreoffice*\n\n$(which libreoffice)\n$(libreoffice --version)"; else echo "ERROR libreoffice not found!"; exit 1; fi
  - if [ "$(which pdflatex)" ]; then echo "\n\n*pdflatex*\n\n$(which pdflatex)\n$(pdflatex --version | grep 'TeX Live')"; else echo "ERROR pdflatex not found!"; exit 1; fi
  - if [ "$(which xelatex)" ]; then echo "\n\n*xelatex*\n\n$(which xelatex)\n$(xelatex --version | grep 'TeX Live')"; else echo "ERROR xelatex not found!"; exit 1; fi
  # Development tools
  - echo "\n... Development tools:\n"
  - if [ "$(which azuredatastudio)" ]; then echo "\n\n*azuredatastudio*\n\n$(which azuredatastudio)"; else echo "ERROR azuredatastudio not found!"; exit 1; fi
  - if [ "$(which bash)" ]; then echo "\n\n*bash*\n\n$(which bash)\n$(bash --version | grep 'version')"; else echo "ERROR bash not found!"; exit 1; fi
  - if [ "$(which dbeaver)" ]; then echo "\n\n*DBeaver*\n\n$(which dbeaver)\n$(dpkg -s dbeaver-ce | grep '^Version:')"; else echo "ERROR DBeaver not found!"; exit 1; fi
  - if [ "$(which docker)" ]; then echo "\n\n*Docker*\n\n$(which docker)\n$(docker --version)\n$(docker image ls)"; else echo "ERROR Docker not found!"; exit 1; fi
  - if [ "$(which firefox)" ]; then echo "\n\n*Firefox*\n\n$(which firefox)\n$(firefox --version)"; else echo "ERROR Firefox not found!"; exit 1; fi
  - if [ "$(which git)" ]; then echo "\n\n*git*\n\n$(which git)\n$(git --version)"; else echo "ERROR git not found!"; exit 1; fi
  - if [ "$(which htop)" ]; then echo "\n\n*htop*\n\n$(which htop)\n$(htop --version)"; else echo "ERROR htop not found!"; exit 1; fi
  - if [ "$(which nvidia-smi)" ]; then echo "\n\n*nvidia-smi*\n\n$(which nvidia-smi)\n$(modinfo nvidia | grep '^version:')"; else echo "nvidia-ERROR smi not found!"; exit 1; fi
  - if [ "$(which psql)" ]; then echo "\n\n*psql*\n\n$(which psql)\n$(psql --version)"; else echo "ERROR psql not found!"; exit 1; fi
  - if [ "$(which sqlcmd)" ]; then echo "\n\n*sqlcmd*\n\n$(which sqlcmd)\n$(sqlcmd -? | grep Version)"; else echo "ERROR sqlcmd not found!"; exit 1; fi
  # Data Science tools
  - if [ "$(which weka)" ]; then echo "\n\n*weka*\n\n$(which weka)\n$(weka -c weka.core.Version | head -n 1)"; else echo "ERROR weka not found!"; exit 1; fi

final_message: "System setup through cloud-init is finished. Configuration took $UPTIME seconds"

# Shutdown at the end of the job to save on running costs
power_state:
  mode: poweroff
  message: "Shutting down after cloud-init is finished"
  timeout: 30
  condition: true
